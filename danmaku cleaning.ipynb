{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99140fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "åŸå§‹æ•°æ®åŸºæœ¬ä¿¡æ¯\n",
      "==================================================\n",
      "æ•°æ®å½¢çŠ¶: (872, 1) (è¡Œæ•°, åˆ—æ•°)\n",
      "\n",
      "åˆ—ååˆ—è¡¨: ['å†…å®¹']\n",
      "\n",
      "å‰5è¡Œæ•°æ®:\n",
      "                  å†…å®¹\n",
      "0  â€œç›´è¡Œæˆ–æ˜¯è½¬å¼¯ï¼Œæˆ‘ä»¬æœ€ç»ˆéƒ½ä¼šç›¸è§â€\n",
      "1    äººå¯ä»¥å¹²å¹²å‡€å‡€çš„èµ°ï¼Œå®ƒä»¬ä¹Ÿå¯ä»¥\n",
      "2       åˆ«è¯´å‚ä¸äº†å°±è¿™ä¹ˆçœ‹éƒ½æ³ªç›®\n",
      "3         ä¹Œé¾Ÿï¼šæˆ‘çš„ç»­èˆªéå¸¸ä¹…\n",
      "4        ç”»é¢è‰²å½©å¯Œå£«å‘³å„¿å¾ˆè¶³å•Š\n",
      "\n",
      "æ•°æ®ç±»å‹:\n",
      "å†…å®¹    object\n",
      "dtype: object\n",
      "\n",
      "ç¼ºå¤±å€¼ç»Ÿè®¡:\n",
      "å†…å®¹    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. è¯»å–Excelæ–‡ä»¶ï¼ŒæŸ¥çœ‹æ•°æ®åŸºæœ¬ä¿¡æ¯\n",
    "# è¯»å–å¼¹å¹•æ•°æ®\n",
    "df = pd.read_excel('D:/CITYU COURSES/5507/homework/å¼¹å¹•/BV17JRKYdEEså¼¹å¹•æ•°æ®.xlsx')\n",
    "\n",
    "# æŸ¥çœ‹æ•°æ®åŸºæœ¬ä¿¡æ¯\n",
    "print(\"=\"*50)\n",
    "print(\"åŸå§‹æ•°æ®åŸºæœ¬ä¿¡æ¯\")\n",
    "print(\"=\"*50)\n",
    "print(f\"æ•°æ®å½¢çŠ¶: {df.shape} (è¡Œæ•°, åˆ—æ•°)\")\n",
    "print(f\"\\nåˆ—ååˆ—è¡¨: {list(df.columns)}\")\n",
    "print(f\"\\nå‰5è¡Œæ•°æ®:\")\n",
    "print(df.head())\n",
    "print(f\"\\næ•°æ®ç±»å‹:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nç¼ºå¤±å€¼ç»Ÿè®¡:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd77000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸè¯»å–æ•°æ®ï¼š872æ¡å¼¹å¹•ï¼Œåˆ—åï¼š['å†…å®¹']\n",
      "\n",
      "ğŸ” æ­£åœ¨è¿‡æ»¤éå® ç‰©æ®¡è‘¬ç›¸å…³å¼¹å¹•...\n",
      "\n",
      "ğŸ“Š è¿‡æ»¤ç»Ÿè®¡ï¼š\n",
      "   â€¢ æ¸…æ´—åæœ‰æ•ˆæ–‡æœ¬ï¼š851 æ¡\n",
      "   â€¢ å‰”é™¤æ— å…³å¼¹å¹•ï¼š657 æ¡\n",
      "   â€¢ æœ€ç»ˆä¿ç•™ç›¸å…³å¼¹å¹•ï¼š194 æ¡\n",
      "\n",
      "============================================================\n",
      "          å® ç‰©æ®¡è‘¬Bç«™å¼¹å¹•æ•°æ®æ¸…æ´—æŠ¥å‘Šï¼ˆæœ€ç»ˆç‰ˆï¼‰\n",
      "============================================================\n",
      "ğŸ“ˆ æ•°æ®è§„æ¨¡ï¼š\n",
      "   â€¢ åŸå§‹æ•°æ®ï¼š872 æ¡\n",
      "   â€¢ å‰”é™¤æ— æ•ˆæ–‡æœ¬ï¼š21 æ¡ï¼ˆæ ¼å¼é”™è¯¯/æ— æ„ä¹‰ï¼‰\n",
      "   â€¢ å‰”é™¤æ— å…³ä¸»é¢˜ï¼š657 æ¡ï¼ˆéå® ç‰©æ®¡è‘¬ï¼‰\n",
      "   â€¢ æœ€ç»ˆæœ‰æ•ˆæ•°æ®ï¼š194 æ¡\n",
      "   â€¢ æ ¸å¿ƒæ•°æ®ä¿ç•™ç‡ï¼š22.25%\n",
      "\n",
      "ğŸ“ æ–‡æœ¬ç‰¹å¾ï¼š\n",
      "   â€¢ å¹³å‡é•¿åº¦ï¼š12.4 å­—ç¬¦\n",
      "   â€¢ æœ€é•¿å¼¹å¹•ï¼š81 å­—ç¬¦\n",
      "   â€¢ æœ€çŸ­å¼¹å¹•ï¼š2 å­—ç¬¦\n",
      "\n",
      "ğŸš« å‰”é™¤çš„æ— å…³å¼¹å¹•ç¤ºä¾‹ï¼ˆå‰5æ¡ï¼‰ï¼š\n",
      "   â€¢ â€œç›´è¡Œæˆ–æ˜¯è½¬å¼¯ï¼Œæˆ‘ä»¬æœ€ç»ˆéƒ½ä¼šç›¸è§â€\n",
      "   â€¢ äººå¯ä»¥å¹²å¹²å‡€å‡€çš„èµ°ï¼Œå®ƒä»¬ä¹Ÿå¯ä»¥\n",
      "   â€¢ ç”»é¢è‰²å½©å¯Œå£«å‘³å„¿å¾ˆè¶³å•Š\n",
      "   â€¢ è®°è€…å†°ä¸Šçº¿\n",
      "   â€¢ â€œæˆ‘ä»¬æœ€ç»ˆéƒ½ä¼šç›¸è§â€\n",
      "\n",
      "âœ… ä¿ç•™çš„ç›¸å…³å¼¹å¹•ç¤ºä¾‹ï¼ˆå‰5æ¡ï¼‰ï¼š\n",
      "   â€¢ åŸå§‹ï¼šåˆ«è¯´å‚ä¸äº†å°±è¿™ä¹ˆçœ‹éƒ½æ³ªç›®\n",
      "   â€¢ æ¸…æ´—ï¼šåˆ«è¯´å‚ä¸äº†å°±è¿™ä¹ˆçœ‹éƒ½æ³ªç›®\n",
      "   â€¢ åŸå§‹ï¼šä¹Œé¾Ÿï¼šæˆ‘çš„ç»­èˆªéå¸¸ä¹…\n",
      "   â€¢ æ¸…æ´—ï¼šä¹Œé¾Ÿï¼šæˆ‘çš„ç»­èˆªéå¸¸ä¹…\n",
      "   â€¢ åŸå§‹ï¼šè‘¬ç¤¼çš„æ„ä¹‰ æ›´å¤šçš„æ˜¯ä¸ºäº†æ´»ç€çš„äººã€‚ä¸€åœºåº„é‡è€Œæ¸©æš–çš„ä»ªå¼å‘Šåˆ« è®©äººå¿ƒç»“ å“€ä¼¤æœ‰æ‰€å¯„æ‰˜ã€‚æ„¿æ‚²ä¼¤è¿œç¦»æˆ‘ä»¬ã€‚\n",
      "   â€¢ æ¸…æ´—ï¼šè‘¬ç¤¼çš„æ„ä¹‰ æ›´å¤šçš„æ˜¯ä¸ºäº†æ´»ç€çš„äººã€‚ä¸€åœºåº„é‡è€Œæ¸©æš–çš„ä»ªå¼å‘Šåˆ« è®©äººå¿ƒç»“ å“€ä¼¤æœ‰æ‰€å¯„æ‰˜ã€‚æ„¿æ‚²ä¼¤è¿œç¦»æˆ‘ä»¬ã€‚\n",
      "   â€¢ åŸå§‹ï¼šæ™šå®‰ï¼ŒçŒ«çŒ«ï½\n",
      "   â€¢ æ¸…æ´—ï¼šæ™šå®‰ï¼ŒçŒ«çŒ«\n",
      "   â€¢ åŸå§‹ï¼šæ„ä¹‰æˆ–è®¸æ˜¯ï¼Œè®©å® ç‰©çš„çµé­‚ä¸ä¼šæ— å®¶å¯å½’å§ï¼ˆï¼‰\n",
      "   â€¢ æ¸…æ´—ï¼šæ„ä¹‰æˆ–è®¸æ˜¯ï¼Œè®©å® ç‰©çš„çµé­‚ä¸ä¼šæ— å®¶å¯å½’å§ï¼ˆï¼‰\n",
      "\n",
      "ğŸ“ è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼šD:\\CITYU COURSES\\5507\\homework\\å¼¹å¹•\\BV17JRKYdEEså¼¹å¹•æ•°æ®_æœ€ç»ˆæ¸…æ´—ç‰ˆ.xlsx\n",
      "============================================================\n",
      "\n",
      "ğŸ‰ æ¸…æ´—å®Œæˆï¼å¯ç›´æ¥ä½¿ç”¨è¾“å‡ºæ–‡ä»¶è¿›è¡Œæƒ…æ„Ÿåˆ†æï½\n"
     ]
    }
   ],
   "source": [
    "# å® ç‰©æ®¡è‘¬Bç«™å¼¹å¹•æ•°æ®æ¸…æ´—æœ€ç»ˆç‰ˆ\n",
    "# ä¿®å¤ï¼šPermissionErroræƒé™é—®é¢˜ + NameErrorå˜é‡é—®é¢˜ + ä¸»é¢˜è¿‡æ»¤\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===================== æ ¸å¿ƒé…ç½®ï¼šä¸»é¢˜å…³é”®è¯ï¼ˆå¯è‡ªå®šä¹‰è°ƒæ•´ï¼‰ =====================\n",
    "# å® ç‰©æ®¡è‘¬ç›¸å…³å…³é”®è¯ï¼ˆè¦†ç›–å® ç‰©ç±»å‹ã€æ®¡è‘¬æœåŠ¡ã€æƒ…æ„Ÿè¡¨è¾¾ï¼‰\n",
    "PET_FUNERAL_KEYWORDS = {\n",
    "    # å® ç‰©ç±»å‹\n",
    "    'çŒ«', 'å–µ', 'çŒ«å’ª', 'å°çŒ«', 'çŒ«ä¸»å­', 'ç‹—', 'æ±ª', 'ç‹—ç‹—', 'å°ç‹—', 'å® ç‰©',\n",
    "    'æ¯›å­©å­', 'ä¸»å­', 'å°å®¶ä¼™', 'å°åŠ¨ç‰©', 'é¾Ÿ', 'ä¹Œé¾Ÿ', 'ä»“é¼ ', 'å…”å­', 'é¾™çŒ«',\n",
    "    # æ®¡è‘¬ç›¸å…³\n",
    "    'æ®¡è‘¬', 'è‘¬ç¤¼', 'å®‰è‘¬', 'ç«åŒ–', 'å‘Šåˆ«', 'é€è¡Œ', 'å®‰æ¯', 'é•¿çœ ', 'ç¦»ä¸–', 'å»ä¸–',\n",
    "    'é€å»', 'ç¦»å¼€', 'èµ°äº†', 'å¾€ç”Ÿ', 'å½’è¥¿', 'åäº‹', 'å‘Šåˆ«ä»ªå¼', 'éª¨ç°', 'å¢“ç¢‘',\n",
    "    # æ ¸å¿ƒæƒ…æ„Ÿ\n",
    "    'æ³ªç›®', 'å“­äº†', 'éš¾è¿‡', 'å¿ƒç–¼', 'æ„ŸåŠ¨', 'æ¸©æš–', 'æ²»æ„ˆ', 'å®‰å¿ƒ', 'ä¸èˆ',\n",
    "    'æ€€å¿µ', 'æ€å¿µ', 'æƒ³å¿µ', 'å°Šé‡', 'ä½“é¢', 'å°Šä¸¥', 'å¥½å¥½å‘Šåˆ«',\n",
    "    # ç›¸å…³æœåŠ¡/åœºæ™¯\n",
    "    'å® ç‰©æ®¡è‘¬', 'å® ç‰©ç«åŒ–', 'å® ç‰©å®‰è‘¬', 'å‘Šåˆ«ä¼š', 'çºªå¿µ', 'çºªå¿µå†Œ', 'éª¨ç°ç›’',\n",
    "    'é€æœ€åä¸€ç¨‹', 'æœ€åçš„å‘Šåˆ«', 'ç”Ÿå‘½', 'æ­»äº¡', 'ä¸´ç»ˆ'\n",
    "}\n",
    "\n",
    "# æ— å…³å†…å®¹å…³é”®è¯ï¼ˆéœ€å‰”é™¤çš„å¼¹å¹•ç±»å‹ï¼‰\n",
    "IRRELEVANT_KEYWORDS = {\n",
    "    'å†°å†°', 'ç‹å†°å†°', 'è®°è€…', 'ä¸»æŒäºº', 'UPä¸»', 'è§†é¢‘', 'ç”»é¢', 'é•œå¤´', 'å‰ªè¾‘',\n",
    "    'é…ä¹', 'BGM', 'å¼¹å¹•', 'è¯„è®º', 'ç‚¹èµ', 'æŠ•å¸', 'æ”¶è—', 'å…³æ³¨', 'è½¬å‘',\n",
    "    'ç›´æ’­', 'æ›´æ–°', 'å‚¬æ›´', 'é¸½å­', 'æ‹–æ›´', 'UP', 'ä¸»æ’­', 'é¢œå€¼', 'èº«æ',\n",
    "    'å¤©æ°”', 'å­£èŠ‚', 'ç¾é£Ÿ', 'æ¸¸æˆ', 'è¿½å‰§', 'å­¦ä¹ ', 'å·¥ä½œ', 'è€ƒè¯•', 'æ”¾å‡'\n",
    "}\n",
    "\n",
    "# ===================== 1. å®‰å…¨ä¿å­˜æ–‡ä»¶ï¼ˆè§£å†³æƒé™é—®é¢˜ï¼‰ =====================\n",
    "def safe_save_excel(df, output_path):\n",
    "    \"\"\"å®‰å…¨ä¿å­˜Excelï¼Œè‡ªåŠ¨å¤„ç†æ–‡ä»¶å ç”¨ã€è·¯å¾„ä¸å­˜åœ¨é—®é¢˜\"\"\"\n",
    "    # åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰\n",
    "    folder_path = os.path.dirname(output_path)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"ğŸ“‚ è‡ªåŠ¨åˆ›å»ºæ–‡ä»¶å¤¹ï¼š{folder_path}\")\n",
    "    \n",
    "    # å¤„ç†æ–‡ä»¶é‡åï¼ˆæ·»åŠ æ—¶é—´æˆ³é¿å…è¦†ç›–ï¼‰\n",
    "    if os.path.exists(output_path):\n",
    "        file_name, ext = os.path.splitext(output_path)\n",
    "        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_path = f\"{file_name}_{timestamp}{ext}\"\n",
    "        print(f\"âš ï¸  åŸæ–‡ä»¶å·²å­˜åœ¨ï¼Œé‡å‘½åä¸ºï¼š{os.path.basename(output_path)}\")\n",
    "    \n",
    "    # 3æ¬¡é‡è¯•ä¿å­˜ï¼ˆè§£å†³æ–‡ä»¶å ç”¨ï¼‰\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            df.to_excel(output_path, index=False, engine='openpyxl')\n",
    "            return output_path  # ä¿å­˜æˆåŠŸï¼Œè¿”å›æœ€ç»ˆè·¯å¾„\n",
    "        except PermissionError:\n",
    "            if i == 2:\n",
    "                print(f\"âŒ ä¿å­˜å¤±è´¥ï¼šç›®æ ‡æ–‡ä»¶è¢«å ç”¨ï¼Œè¯·å…³é—­ç›¸å…³Excelåé‡è¯•\")\n",
    "                return None\n",
    "            print(f\"âš ï¸ æ–‡ä»¶è¢«å ç”¨ï¼Œ{3-i}ç§’åé‡è¯•...\")\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ä¿å­˜å¤±è´¥ï¼š{str(e)}\")\n",
    "            return None\n",
    "\n",
    "# ===================== 2. æ•°æ®è¯»å– =====================\n",
    "def load_data(file_path):\n",
    "    \"\"\"è¯»å–åŸå§‹å¼¹å¹•æ•°æ®\"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        print(f\"âœ… æˆåŠŸè¯»å–æ•°æ®ï¼š{len(df)}æ¡å¼¹å¹•ï¼Œåˆ—åï¼š{df.columns.tolist()}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¯»å–å¤±è´¥ï¼š{str(e)}\")\n",
    "        print(\"è¯·æ£€æŸ¥ï¼š1.æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡® 2.æ–‡ä»¶æ˜¯å¦è¢«æ‰“å¼€ 3.æ˜¯å¦å®‰è£…openpyxlï¼ˆpip install openpyxlï¼‰\")\n",
    "        return None\n",
    "\n",
    "# ===================== 3. ä¸»é¢˜ç›¸å…³æ€§åˆ¤æ–­ï¼ˆæ ¸å¿ƒè¿‡æ»¤ï¼‰ =====================\n",
    "def is_relevant(text):\n",
    "    \"\"\"åˆ¤æ–­å¼¹å¹•æ˜¯å¦ä¸å® ç‰©æ®¡è‘¬ç›¸å…³\"\"\"\n",
    "    if not text:\n",
    "        return False\n",
    "    \n",
    "    # æ­£å‘åŒ¹é…ï¼šåŒ…å«ç›¸å…³å…³é”®è¯ â†’ ä¿ç•™\n",
    "    for kw in PET_FUNERAL_KEYWORDS:\n",
    "        if kw in text:\n",
    "            return True\n",
    "    \n",
    "    # åå‘æ’é™¤ï¼šåŒ…å«æ— å…³å…³é”®è¯ â†’ å‰”é™¤\n",
    "    for kw in IRRELEVANT_KEYWORDS:\n",
    "        if kw in text:\n",
    "            return False\n",
    "    \n",
    "    # æƒ…æ„Ÿ+åœºæ™¯åŒ¹é…ï¼šæ— å…³é”®è¯ä½†ç¬¦åˆä¸»é¢˜ â†’ ä¿ç•™\n",
    "    emotion_words = {'æ³ªç›®', 'å“­äº†', 'éš¾è¿‡', 'å¿ƒç–¼', 'æ„ŸåŠ¨', 'ä¸èˆ', 'æ€€å¿µ'}\n",
    "    pet_leave_words = {'çŒ«', 'ç‹—', 'å® ç‰©', 'æ¯›å­©å­', 'ç¦»å¼€', 'èµ°äº†', 'é€å»', 'å‘Šåˆ«'}\n",
    "    if any(w in text for w in emotion_words) and any(w in text for w in pet_leave_words):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# ===================== 4. å¼¹å¹•æ–‡æœ¬æ¸…æ´— =====================\n",
    "def clean_text(text):\n",
    "    \"\"\"æ¸…æ´—æ–‡æœ¬ï¼šå»é™¤å¹²æ‰°å­—ç¬¦ã€æ ‡å‡†åŒ–æ ¼å¼\"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "    \n",
    "    # åŸºç¡€æ¸…ç†\n",
    "    text = str(text).strip()\n",
    "    text = re.sub(r'[\\n\\r\\t]', '', text)  # å»é™¤æ¢è¡Œ/åˆ¶è¡¨ç¬¦\n",
    "    text = re.sub(r'\\s+', ' ', text)      # å¤šä¸ªç©ºæ ¼â†’å•ä¸ªç©ºæ ¼\n",
    "    \n",
    "    # è¿‡æ»¤ç‰¹æ®Šç¬¦å·ï¼ˆä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€å¸¸è§æ ‡ç‚¹ï¼‰\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5a-zA-Z0-9ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š\"\"''ï¼ˆï¼‰ã€ã€‘ã€Â·â€¦â€”\\s]', '', text)\n",
    "    \n",
    "    # å»é™¤æ— æ„ä¹‰æ–‡æœ¬ï¼ˆé•¿åº¦<2ä¸”éæƒ…æ„Ÿè¯ï¼‰\n",
    "    meaningless = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'å’Œ', 'å•Š', 'å‘€', 'å‘¢', 'å“¦', 'å§'}\n",
    "    if len(text) < 2 or (len(text) == 1 and text in meaningless):\n",
    "        return ''\n",
    "    \n",
    "    # ç®€åŒ–é‡å¤å­—ç¬¦ï¼ˆå¦‚\"å‘œå‘œå‘œå‘œ\"â†’\"å‘œå‘œ\"ï¼‰\n",
    "    text = re.sub(r'(.)\\1{3,}', r'\\1\\1', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# ===================== 5. å®Œæ•´å¤„ç†æµç¨‹ =====================\n",
    "def process_data(df_original, output_path):\n",
    "    \"\"\"æ¸…æ´—+è¿‡æ»¤+ä¿å­˜å®Œæ•´æµç¨‹\"\"\"\n",
    "    # æ­¥éª¤1ï¼šåŸºç¡€æ–‡æœ¬æ¸…æ´—\n",
    "    df_original['æ¸…æ´—åå†…å®¹'] = df_original['å†…å®¹'].apply(clean_text)\n",
    "    df_cleaned = df_original[df_original['æ¸…æ´—åå†…å®¹'] != ''].copy()  # å‰”é™¤æ— æ•ˆæ–‡æœ¬\n",
    "    \n",
    "    # æ­¥éª¤2ï¼šä¸»é¢˜è¿‡æ»¤ï¼ˆæ ¸å¿ƒï¼‰\n",
    "    print(f\"\\nğŸ” æ­£åœ¨è¿‡æ»¤éå® ç‰©æ®¡è‘¬ç›¸å…³å¼¹å¹•...\")\n",
    "    df_cleaned['æ˜¯å¦ç›¸å…³'] = df_cleaned['æ¸…æ´—åå†…å®¹'].apply(is_relevant)\n",
    "    df_final = df_cleaned[df_cleaned['æ˜¯å¦ç›¸å…³'] == True].copy().reset_index(drop=True)\n",
    "    df_irrelevant = df_cleaned[df_cleaned['æ˜¯å¦ç›¸å…³'] == False].copy()\n",
    "    \n",
    "    # æ­¥éª¤3ï¼šæ·»åŠ è¾…åŠ©åˆ—\n",
    "    df_final['å¼¹å¹•åºå·'] = range(1, len(df_final) + 1)\n",
    "    df_final['æ–‡æœ¬é•¿åº¦'] = df_final['æ¸…æ´—åå†…å®¹'].apply(len)\n",
    "    \n",
    "    # æ­¥éª¤4ï¼šæ•´ç†è¾“å‡ºæ ¼å¼\n",
    "    df_output = df_final[['å¼¹å¹•åºå·', 'å†…å®¹', 'æ¸…æ´—åå†…å®¹', 'æ–‡æœ¬é•¿åº¦']].copy()\n",
    "    df_output.rename(columns={'å†…å®¹': 'åŸå§‹å†…å®¹'}, inplace=True)\n",
    "    \n",
    "    # æ­¥éª¤5ï¼šå®‰å…¨ä¿å­˜\n",
    "    save_path = safe_save_excel(df_output, output_path)\n",
    "    \n",
    "    # è¾“å‡ºç»Ÿè®¡\n",
    "    print(f\"\\nğŸ“Š è¿‡æ»¤ç»Ÿè®¡ï¼š\")\n",
    "    print(f\"   â€¢ æ¸…æ´—åæœ‰æ•ˆæ–‡æœ¬ï¼š{len(df_cleaned)} æ¡\")\n",
    "    print(f\"   â€¢ å‰”é™¤æ— å…³å¼¹å¹•ï¼š{len(df_irrelevant)} æ¡\")\n",
    "    print(f\"   â€¢ æœ€ç»ˆä¿ç•™ç›¸å…³å¼¹å¹•ï¼š{len(df_final)} æ¡\")\n",
    "    \n",
    "    return df_output, df_irrelevant, save_path\n",
    "\n",
    "# ===================== 6. ç”Ÿæˆæ¸…æ´—æŠ¥å‘Š =====================\n",
    "def generate_report(df_original, df_final, df_irrelevant, save_path):\n",
    "    \"\"\"ç”Ÿæˆè¯¦ç»†æ¸…æ´—æŠ¥å‘Š\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"          å® ç‰©æ®¡è‘¬Bç«™å¼¹å¹•æ•°æ®æ¸…æ´—æŠ¥å‘Šï¼ˆæœ€ç»ˆç‰ˆï¼‰\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # åŸºç¡€ç»Ÿè®¡\n",
    "    total_original = len(df_original)\n",
    "    total_final = len(df_final)\n",
    "    filtered_invalid = total_original - len(df_original[df_original['æ¸…æ´—åå†…å®¹'] != ''])\n",
    "    filtered_irrelevant = len(df_irrelevant)\n",
    "    \n",
    "    print(f\"ğŸ“ˆ æ•°æ®è§„æ¨¡ï¼š\")\n",
    "    print(f\"   â€¢ åŸå§‹æ•°æ®ï¼š{total_original} æ¡\")\n",
    "    print(f\"   â€¢ å‰”é™¤æ— æ•ˆæ–‡æœ¬ï¼š{filtered_invalid} æ¡ï¼ˆæ ¼å¼é”™è¯¯/æ— æ„ä¹‰ï¼‰\")\n",
    "    print(f\"   â€¢ å‰”é™¤æ— å…³ä¸»é¢˜ï¼š{filtered_irrelevant} æ¡ï¼ˆéå® ç‰©æ®¡è‘¬ï¼‰\")\n",
    "    print(f\"   â€¢ æœ€ç»ˆæœ‰æ•ˆæ•°æ®ï¼š{total_final} æ¡\")\n",
    "    print(f\"   â€¢ æ ¸å¿ƒæ•°æ®ä¿ç•™ç‡ï¼š{round(total_final/total_original*100, 2)}%\")\n",
    "    \n",
    "    # æ–‡æœ¬ç‰¹å¾\n",
    "    if total_final > 0:\n",
    "        avg_len = round(df_final['æ–‡æœ¬é•¿åº¦'].mean(), 2)\n",
    "        print(f\"\\nğŸ“ æ–‡æœ¬ç‰¹å¾ï¼š\")\n",
    "        print(f\"   â€¢ å¹³å‡é•¿åº¦ï¼š{avg_len} å­—ç¬¦\")\n",
    "        print(f\"   â€¢ æœ€é•¿å¼¹å¹•ï¼š{df_final['æ–‡æœ¬é•¿åº¦'].max()} å­—ç¬¦\")\n",
    "        print(f\"   â€¢ æœ€çŸ­å¼¹å¹•ï¼š{df_final['æ–‡æœ¬é•¿åº¦'].min()} å­—ç¬¦\")\n",
    "    \n",
    "    # æ— å…³å¼¹å¹•ç¤ºä¾‹ï¼ˆä¾¿äºè°ƒæ•´å…³é”®è¯ï¼‰\n",
    "    print(f\"\\nğŸš« å‰”é™¤çš„æ— å…³å¼¹å¹•ç¤ºä¾‹ï¼ˆå‰5æ¡ï¼‰ï¼š\")\n",
    "    for idx, row in df_irrelevant.head(5).iterrows():\n",
    "        print(f\"   â€¢ {row['å†…å®¹']}\")\n",
    "    \n",
    "    # æœ€ç»ˆæœ‰æ•ˆæ•°æ®ç¤ºä¾‹\n",
    "    print(f\"\\nâœ… ä¿ç•™çš„ç›¸å…³å¼¹å¹•ç¤ºä¾‹ï¼ˆå‰5æ¡ï¼‰ï¼š\")\n",
    "    for idx, row in df_final.head(5).iterrows():\n",
    "        print(f\"   â€¢ åŸå§‹ï¼š{row['åŸå§‹å†…å®¹']}\")\n",
    "        print(f\"   â€¢ æ¸…æ´—ï¼š{row['æ¸…æ´—åå†…å®¹']}\")\n",
    "    \n",
    "    if save_path:\n",
    "        print(f\"\\nğŸ“ è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼š{save_path}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# ===================== ä¸»å‡½æ•°ï¼ˆç›´æ¥è¿è¡Œï¼‰ =====================\n",
    "def main():\n",
    "    # ---------------------- è¯·ä¿®æ”¹è¿™é‡Œçš„è·¯å¾„ ----------------------\n",
    "    INPUT_FILE = r\"D:\\CITYU COURSES\\5507\\homework\\å¼¹å¹•\\BV17JRKYdEEså¼¹å¹•æ•°æ®.xlsx\"\n",
    "    OUTPUT_FILE = r\"D:\\CITYU COURSES\\5507\\homework\\å¼¹å¹•\\BV17JRKYdEEså¼¹å¹•æ•°æ®_æœ€ç»ˆæ¸…æ´—ç‰ˆ.xlsx\"\n",
    "    # -------------------------------------------------------------\n",
    "    \n",
    "    # æ‰§è¡Œæµç¨‹\n",
    "    df_original = load_data(INPUT_FILE)\n",
    "    if df_original is None:\n",
    "        return\n",
    "    \n",
    "    df_final, df_irrelevant, save_path = process_data(df_original, OUTPUT_FILE)\n",
    "    generate_report(df_original, df_final, df_irrelevant, save_path)\n",
    "    print(\"\\nğŸ‰ æ¸…æ´—å®Œæˆï¼å¯ç›´æ¥ä½¿ç”¨è¾“å‡ºæ–‡ä»¶è¿›è¡Œæƒ…æ„Ÿåˆ†æï½\")\n",
    "\n",
    "# è¿è¡Œä¸»å‡½æ•°\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca356c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸè¯»å–æ•°æ®ï¼š507æ¡è®°å½•ï¼Œåˆ—åï¼š['å¼¹å¹•å†…å®¹']\n",
      "âœ… è‡ªåŠ¨è¯†åˆ«å¼¹å¹•åˆ—ï¼šå¼¹å¹•å†…å®¹\n",
      "\n",
      "ğŸ”§ æ­£åœ¨æ¸…æ´—å¼¹å¹•å†…å®¹åˆ—...\n",
      "   æ¸…æ´—å®Œæˆï¼šå‰”é™¤æ— æ•ˆæ–‡æœ¬12æ¡ï¼Œå‰©ä½™495æ¡\n",
      "\n",
      "ğŸ¯ è¿‡æ»¤éå® ç‰©æ®¡è‘¬ç›¸å…³å¼¹å¹•...\n",
      "   è¿‡æ»¤å®Œæˆï¼šå‰”é™¤æ— å…³å¼¹å¹•317æ¡ï¼Œä¿ç•™178æ¡ç›¸å…³å¼¹å¹•\n",
      "\n",
      "==================================================\n",
      "          æ¸…æ´—æŠ¥å‘Šï¼ˆBV1AU4y1u79zï¼‰\n",
      "==================================================\n",
      "ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼š\n",
      "   â€¢ åŸå§‹æ•°æ®ï¼š507æ¡\n",
      "   â€¢ æœ€ç»ˆç›¸å…³æ•°æ®ï¼š178æ¡\n",
      "   â€¢ ä¿ç•™ç‡ï¼š35.11%\n",
      "ğŸ“ æ–‡æœ¬ç‰¹å¾ï¼š\n",
      "   â€¢ å¹³å‡é•¿åº¦ï¼š19.97å­—ç¬¦\n",
      "==================================================\n",
      "\n",
      "ğŸ‰ æ¸…æ´—å®Œæˆï¼æ–‡ä»¶è·¯å¾„ï¼šD:\\CITYU COURSES\\5507\\homework\\å¼¹å¹•\\BV1AU4y1u79zå¼¹å¹•æ•°æ®_æ¸…æ´—å®Œæˆç‰ˆ.xlsx\n",
      "   å¯ç›´æ¥ç”¨äºå® ç‰©æ®¡è‘¬æƒ…æ„Ÿåˆ†æï½\n"
     ]
    }
   ],
   "source": [
    "# å® ç‰©æ®¡è‘¬Bç«™å¼¹å¹•æ¸…æ´—ä»£ç ï¼ˆä¿®å¤KeyErrorï¼Œé€‚é…BV1AU4y1u79zï¼‰\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===================== 1. æ ¸å¿ƒé…ç½®ï¼šä¸»é¢˜å…³é”®è¯ =====================\n",
    "RELEVANT_KEYWORDS = {\n",
    "    # å® ç‰©ç±»å‹\n",
    "    'çŒ«', 'å–µ', 'çŒ«å’ª', 'å°çŒ«', 'çŒ«ä¸»å­', 'ç‹—', 'æ±ª', 'ç‹—ç‹—', 'å°ç‹—', 'å® ç‰©',\n",
    "    'æ¯›å­©å­', 'ä¸»å­', 'å°å®¶ä¼™', 'å°åŠ¨ç‰©', 'é¾Ÿ', 'ä¹Œé¾Ÿ', 'ä»“é¼ ', 'å…”å­', 'é¾™çŒ«',\n",
    "    # æ®¡è‘¬ç›¸å…³\n",
    "    'æ®¡è‘¬', 'è‘¬ç¤¼', 'å®‰è‘¬', 'ç«åŒ–', 'å‘Šåˆ«', 'é€è¡Œ', 'å®‰æ¯', 'é•¿çœ ', 'ç¦»ä¸–', 'å»ä¸–',\n",
    "    'é€å»', 'ç¦»å¼€', 'èµ°äº†', 'å¾€ç”Ÿ', 'åäº‹', 'å‘Šåˆ«ä»ªå¼', 'éª¨ç°', 'å¢“ç¢‘',\n",
    "    # æ ¸å¿ƒæƒ…æ„Ÿ\n",
    "    'æ³ªç›®', 'å“­äº†', 'éš¾è¿‡', 'å¿ƒç–¼', 'æ„ŸåŠ¨', 'æ¸©æš–', 'æ²»æ„ˆ', 'å®‰å¿ƒ', 'ä¸èˆ',\n",
    "    'æ€€å¿µ', 'æ€å¿µ', 'å°Šé‡', 'ä½“é¢', 'å¥½å¥½å‘Šåˆ«',\n",
    "    # åœºæ™¯ç›¸å…³\n",
    "    'å® ç‰©æ®¡è‘¬', 'å® ç‰©ç«åŒ–', 'å® ç‰©å®‰è‘¬', 'é€æœ€åä¸€ç¨‹', 'æœ€åçš„å‘Šåˆ«'\n",
    "}\n",
    "\n",
    "IRRELEVANT_KEYWORDS = {\n",
    "    'UPä¸»', 'è§†é¢‘', 'ç”»é¢', 'å‰ªè¾‘', 'é…ä¹', 'BGM', 'å¼¹å¹•', 'è¯„è®º',\n",
    "    'ç‚¹èµ', 'æŠ•å¸', 'æ”¶è—', 'å…³æ³¨', 'ç›´æ’­', 'æ›´æ–°', 'å‚¬æ›´', 'ä¸»æ’­',\n",
    "    'å¤©æ°”', 'å­£èŠ‚', 'ç¾é£Ÿ', 'æ¸¸æˆ', 'è¿½å‰§', 'å­¦ä¹ ', 'å·¥ä½œ', 'è€ƒè¯•'\n",
    "}\n",
    "\n",
    "# ===================== 2. å·¥å…·å‡½æ•°ï¼šè‡ªåŠ¨è¯†åˆ«å¼¹å¹•åˆ—å =====================\n",
    "def get_comment_column(df):\n",
    "    \"\"\"è‡ªåŠ¨è¯†åˆ«å¼¹å¹•å†…å®¹åˆ—ï¼ˆåº”å¯¹ä¸åŒåˆ—åæ ¼å¼ï¼‰\"\"\"\n",
    "    # å¸¸è§å¼¹å¹•åˆ—ååˆ—è¡¨\n",
    "    possible_columns = ['å†…å®¹', 'å¼¹å¹•å†…å®¹', 'comment', 'danmu', 'å¼¹å¹•', 'text']\n",
    "    \n",
    "    # åŒ¹é…åˆ—åï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰\n",
    "    for col in df.columns:\n",
    "        col_lower = str(col).lower()\n",
    "        for possible in possible_columns:\n",
    "            if possible in str(col) or possible.lower() in col_lower:\n",
    "                print(f\"âœ… è‡ªåŠ¨è¯†åˆ«å¼¹å¹•åˆ—ï¼š{col}\")\n",
    "                return col\n",
    "    \n",
    "    # è‹¥æœªåŒ¹é…åˆ°ï¼Œæç¤ºç”¨æˆ·é€‰æ‹©\n",
    "    print(f\"\\nâš ï¸  æœªè‡ªåŠ¨è¯†åˆ«å¼¹å¹•åˆ—ï¼Œå½“å‰åˆ—åï¼š{df.columns.tolist()}\")\n",
    "    while True:\n",
    "        selected_col = input(\"è¯·è¾“å…¥å¼¹å¹•å†…å®¹æ‰€åœ¨åˆ—åï¼ˆç›´æ¥å¤åˆ¶åˆ—åï¼‰ï¼š\")\n",
    "        if selected_col in df.columns:\n",
    "            return selected_col\n",
    "        print(f\"âŒ åˆ—å{selected_col}ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥ï¼\")\n",
    "\n",
    "# ===================== 3. å·¥å…·å‡½æ•°ï¼šå®‰å…¨ä¿å­˜æ–‡ä»¶ =====================\n",
    "def safe_save_excel(df, output_path):\n",
    "    folder = os.path.dirname(output_path)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        name, ext = os.path.splitext(output_path)\n",
    "        timestamp = time.strftime(\"%Y%m%d_%H%M\")\n",
    "        output_path = f\"{name}_{timestamp}{ext}\"\n",
    "    \n",
    "    for i in range(3):\n",
    "        try:\n",
    "            df.to_excel(output_path, index=False, engine='openpyxl')\n",
    "            return output_path\n",
    "        except PermissionError:\n",
    "            if i == 2:\n",
    "                print(f\"âŒ ä¿å­˜å¤±è´¥ï¼šæ–‡ä»¶è¢«å ç”¨ï¼Œè¯·å…³é—­Excelåé‡è¯•\")\n",
    "                return None\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ä¿å­˜å¤±è´¥ï¼š{str(e)}\")\n",
    "            return None\n",
    "\n",
    "# ===================== 4. æ ¸å¿ƒæ¸…æ´—å‡½æ•° =====================\n",
    "def clean_bullet_text(text):\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "    \n",
    "    # åŸºç¡€æ ¼å¼æ¸…ç†\n",
    "    text = str(text).strip()\n",
    "    text = re.sub(r'[\\n\\r\\t]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # è¿‡æ»¤ç‰¹æ®Šç¬¦å·\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5a-zA-Z0-9ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š\"\"''ï¼ˆï¼‰ã€ã€‘ã€Â·â€¦â€”\\s]', '', text)\n",
    "    \n",
    "    # å»é™¤æ— æ„ä¹‰æ–‡æœ¬\n",
    "    meaningless = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'å’Œ', 'å•Š', 'å‘€', 'å‘¢', 'å“¦', 'å§'}\n",
    "    if len(text) < 2 or (len(text) == 1 and text in meaningless):\n",
    "        return ''\n",
    "    \n",
    "    # ç®€åŒ–é‡å¤å­—ç¬¦\n",
    "    text = re.sub(r'(.)\\1{3,}', r'\\1\\1', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# ===================== 5. ä¸»é¢˜è¿‡æ»¤å‡½æ•° =====================\n",
    "def is_pet_funeral_related(text):\n",
    "    if not text:\n",
    "        return False\n",
    "    \n",
    "    # æ­£å‘åŒ¹é…ç›¸å…³å…³é”®è¯\n",
    "    for kw in RELEVANT_KEYWORDS:\n",
    "        if kw in text:\n",
    "            return True\n",
    "    \n",
    "    # åå‘æ’é™¤æ— å…³å…³é”®è¯\n",
    "    for kw in IRRELEVANT_KEYWORDS:\n",
    "        if kw in text:\n",
    "            return False\n",
    "    \n",
    "    # æƒ…æ„Ÿ+åœºæ™¯è¡¥å……åŒ¹é…\n",
    "    emotion_words = {'æ³ªç›®', 'å“­äº†', 'éš¾è¿‡', 'å¿ƒç–¼', 'æ„ŸåŠ¨', 'ä¸èˆ', 'æ€€å¿µ'}\n",
    "    pet_leave_words = {'çŒ«', 'ç‹—', 'å® ç‰©', 'æ¯›å­©å­', 'ç¦»å¼€', 'èµ°äº†', 'é€å»', 'å‘Šåˆ«'}\n",
    "    if any(w in text for w in emotion_words) and any(w in text for w in pet_leave_words):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# ===================== 6. å®Œæ•´æ¸…æ´—æµç¨‹ï¼ˆè‡ªåŠ¨é€‚é…åˆ—åï¼‰ =====================\n",
    "def full_clean_process(input_path, output_path):\n",
    "    # æ­¥éª¤1ï¼šè¯»å–æ•°æ®å¹¶è¯†åˆ«å¼¹å¹•åˆ—\n",
    "    try:\n",
    "        df_original = pd.read_excel(input_path)\n",
    "        print(f\"âœ… æˆåŠŸè¯»å–æ•°æ®ï¼š{len(df_original)}æ¡è®°å½•ï¼Œåˆ—åï¼š{df_original.columns.tolist()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¯»å–å¤±è´¥ï¼š{str(e)}\")\n",
    "        print(\"è¯·æ£€æŸ¥è·¯å¾„æˆ–å®‰è£…openpyxlï¼ˆpip install openpyxlï¼‰\")\n",
    "        return None, None\n",
    "    \n",
    "    # è‡ªåŠ¨è·å–å¼¹å¹•åˆ—å\n",
    "    comment_col = get_comment_column(df_original)\n",
    "    \n",
    "    # æ­¥éª¤2ï¼šæ–‡æœ¬æ¸…æ´—\n",
    "    print(f\"\\nğŸ”§ æ­£åœ¨æ¸…æ´—{comment_col}åˆ—...\")\n",
    "    df_original['æ¸…æ´—åå†…å®¹'] = df_original[comment_col].apply(clean_bullet_text)\n",
    "    df_cleaned = df_original[df_original['æ¸…æ´—åå†…å®¹'] != ''].copy()\n",
    "    print(f\"   æ¸…æ´—å®Œæˆï¼šå‰”é™¤æ— æ•ˆæ–‡æœ¬{len(df_original)-len(df_cleaned)}æ¡ï¼Œå‰©ä½™{len(df_cleaned)}æ¡\")\n",
    "    \n",
    "    # æ­¥éª¤3ï¼šä¸»é¢˜è¿‡æ»¤\n",
    "    print(f\"\\nğŸ¯ è¿‡æ»¤éå® ç‰©æ®¡è‘¬ç›¸å…³å¼¹å¹•...\")\n",
    "    df_cleaned['æ˜¯å¦ç›¸å…³'] = df_cleaned['æ¸…æ´—åå†…å®¹'].apply(is_pet_funeral_related)\n",
    "    df_final = df_cleaned[df_cleaned['æ˜¯å¦ç›¸å…³'] == True].copy().reset_index(drop=True)\n",
    "    print(f\"   è¿‡æ»¤å®Œæˆï¼šå‰”é™¤æ— å…³å¼¹å¹•{len(df_cleaned)-len(df_final)}æ¡ï¼Œä¿ç•™{len(df_final)}æ¡ç›¸å…³å¼¹å¹•\")\n",
    "    \n",
    "    # æ­¥éª¤4ï¼šæ•´ç†è¾“å‡ºæ ¼å¼\n",
    "    df_final['å¼¹å¹•åºå·'] = range(1, len(df_final)+1)\n",
    "    df_final['æ–‡æœ¬é•¿åº¦'] = df_final['æ¸…æ´—åå†…å®¹'].apply(len)\n",
    "    \n",
    "    # ä¿ç•™åŸå§‹å†…å®¹åˆ—ï¼ˆé‡å‘½åä¸ºç»Ÿä¸€çš„â€œåŸå§‹å†…å®¹â€ï¼‰\n",
    "    df_output = df_final.rename(columns={comment_col: 'åŸå§‹å†…å®¹'})\n",
    "    df_output = df_output[['å¼¹å¹•åºå·', 'åŸå§‹å†…å®¹', 'æ¸…æ´—åå†…å®¹', 'æ–‡æœ¬é•¿åº¦']].copy()\n",
    "    \n",
    "    # æ­¥éª¤5ï¼šå®‰å…¨ä¿å­˜\n",
    "    save_path = safe_save_excel(df_output, output_path)\n",
    "    \n",
    "    # æ­¥éª¤6ï¼šè¾“å‡ºæŠ¥å‘Š\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(\"          æ¸…æ´—æŠ¥å‘Šï¼ˆBV1AU4y1u79zï¼‰\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼š\")\n",
    "    print(f\"   â€¢ åŸå§‹æ•°æ®ï¼š{len(df_original)}æ¡\")\n",
    "    print(f\"   â€¢ æœ€ç»ˆç›¸å…³æ•°æ®ï¼š{len(df_final)}æ¡\")\n",
    "    print(f\"   â€¢ ä¿ç•™ç‡ï¼š{round(len(df_final)/len(df_original)*100, 2)}%\")\n",
    "    if len(df_final) > 0:\n",
    "        print(f\"ğŸ“ æ–‡æœ¬ç‰¹å¾ï¼š\")\n",
    "        print(f\"   â€¢ å¹³å‡é•¿åº¦ï¼š{round(df_final['æ–‡æœ¬é•¿åº¦'].mean(), 2)}å­—ç¬¦\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return df_output, save_path\n",
    "\n",
    "# ===================== ä¸»æ‰§è¡Œå‡½æ•° =====================\n",
    "if __name__ == \"__main__\":\n",
    "    # ---------------------- æœ¬åœ°è·¯å¾„é…ç½® ----------------------\n",
    "    INPUT_FILE_PATH = r\"D:\\CITYU COURSES\\5507\\homework\\å¼¹å¹•\\BV1AU4y1u79zå¼¹å¹•æ•°æ®.xlsx\"\n",
    "    OUTPUT_FILE_PATH = r\"D:\\CITYU COURSES\\5507\\homework\\å¼¹å¹•\\BV1AU4y1u79zå¼¹å¹•æ•°æ®_æ¸…æ´—å®Œæˆç‰ˆ.xlsx\"\n",
    "    # ----------------------------------------------------------\n",
    "    \n",
    "    # æ‰§è¡Œæ¸…æ´—\n",
    "    cleaned_df, save_path = full_clean_process(INPUT_FILE_PATH, OUTPUT_FILE_PATH)\n",
    "    if cleaned_df is not None and save_path:\n",
    "        print(f\"\\nğŸ‰ æ¸…æ´—å®Œæˆï¼æ–‡ä»¶è·¯å¾„ï¼š{save_path}\")\n",
    "        print(\"   å¯ç›´æ¥ç”¨äºå® ç‰©æ®¡è‘¬æƒ…æ„Ÿåˆ†æï½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33964fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸè¯»å–æ•°æ®ï¼šå…±793æ¡è®°å½•\n",
      "âœ… è‡ªåŠ¨è¯†åˆ«å¼¹å¹•åˆ—ï¼šã€å¼¹å¹•å†…å®¹ã€‘\n",
      "\n",
      "ğŸ”§ å¼€å§‹æ–‡æœ¬æ¸…æ´—...\n",
      "   æ¸…æ´—å®Œæˆï¼šå‰”é™¤æ— æ•ˆæ–‡æœ¬12æ¡ï¼Œå‰©ä½™781æ¡æœ‰æ•ˆæ–‡æœ¬\n",
      "\n",
      "ğŸ¯ å¼€å§‹å® ç‰©æ®¡è‘¬ä¸»é¢˜è¿‡æ»¤...\n",
      "   è¿‡æ»¤å®Œæˆï¼šå‰”é™¤æ— å…³å¼¹å¹•593æ¡ï¼Œä¿ç•™188æ¡ç›¸å…³å¼¹å¹•\n",
      "\n",
      "============================================================\n",
      "          å® ç‰©æ®¡è‘¬å¼¹å¹•æ¸…æ´—æŠ¥å‘Šï¼ˆBV1iJ4m1G7kJï¼‰\n",
      "============================================================\n",
      "ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼š\n",
      "   â€¢ åŸå§‹æ•°æ®æ€»é‡ï¼š793æ¡\n",
      "   â€¢ æœ€ç»ˆç›¸å…³æ•°æ®ï¼š188æ¡\n",
      "   â€¢ æ•°æ®ä¿ç•™ç‡ï¼š23.71%\n",
      "ğŸ“ æ–‡æœ¬ç‰¹å¾ï¼š\n",
      "   â€¢ å¹³å‡æ–‡æœ¬é•¿åº¦ï¼š18.71å­—ç¬¦\n",
      "   â€¢ æœ€é•¿å¼¹å¹•é•¿åº¦ï¼š64å­—ç¬¦\n",
      "   â€¢ æœ€çŸ­å¼¹å¹•é•¿åº¦ï¼š2å­—ç¬¦\n",
      "\n",
      "ğŸ“ è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼šD:\\CITYU COURSES\\5507\\homework\\å¼¹å¹•\\BV1iJ4m1G7kJå¼¹å¹•æ•°æ®_æ¸…æ´—å®Œæˆç‰ˆ.xlsx\n",
      "============================================================\n",
      "\n",
      "ğŸ‰ æ¸…æ´—ä»»åŠ¡å®Œæˆï¼å¯ç›´æ¥ä½¿ç”¨ã€BV1iJ4m1G7kJå¼¹å¹•æ•°æ®_æ¸…æ´—å®Œæˆç‰ˆ.xlsxã€‘åˆ¶ä½œæƒ…æ„Ÿåˆ†æå›¾ï½\n"
     ]
    }
   ],
   "source": [
    "# å® ç‰©æ®¡è‘¬Bç«™å¼¹å¹•æ¸…æ´—ä»£ç ï¼ˆé€‚é…BV1iJ4m1G7kJæ–‡ä»¶ï¼‰\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===================== 1. æ ¸å¿ƒé…ç½®ï¼šå® ç‰©æ®¡è‘¬ä¸»é¢˜å…³é”®è¯ =====================\n",
    "# ç›¸å…³å…³é”®è¯ï¼ˆè¦†ç›–å® ç‰©ç±»å‹ã€æ®¡è‘¬åœºæ™¯ã€æƒ…æ„Ÿè¡¨è¾¾ï¼Œç¡®ä¿ä¸»é¢˜ç²¾å‡†ï¼‰\n",
    "RELEVANT_KEYWORDS = {\n",
    "    # å® ç‰©ç±»å‹\n",
    "    'çŒ«', 'å–µ', 'çŒ«å’ª', 'å°çŒ«', 'çŒ«ä¸»å­', 'ç‹—', 'æ±ª', 'ç‹—ç‹—', 'å°ç‹—', 'å® ç‰©',\n",
    "    'æ¯›å­©å­', 'ä¸»å­', 'å°å®¶ä¼™', 'å°åŠ¨ç‰©', 'é¾Ÿ', 'ä¹Œé¾Ÿ', 'ä»“é¼ ', 'å…”å­', 'é¾™çŒ«',\n",
    "    'é¹¦é¹‰', 'é¸Ÿ', 'é±¼', 'è·å…°çŒª', 'è±šé¼ ',\n",
    "    # æ®¡è‘¬ç›¸å…³\n",
    "    'æ®¡è‘¬', 'è‘¬ç¤¼', 'å®‰è‘¬', 'ç«åŒ–', 'å‘Šåˆ«', 'é€è¡Œ', 'å®‰æ¯', 'é•¿çœ ', 'ç¦»ä¸–', 'å»ä¸–',\n",
    "    'é€å»', 'ç¦»å¼€', 'èµ°äº†', 'å¾€ç”Ÿ', 'åäº‹', 'å‘Šåˆ«ä»ªå¼', 'éª¨ç°', 'å¢“ç¢‘', 'ä¸‹è‘¬',\n",
    "    # æ ¸å¿ƒæƒ…æ„Ÿ\n",
    "    'æ³ªç›®', 'å“­äº†', 'éš¾è¿‡', 'å¿ƒç–¼', 'æ„ŸåŠ¨', 'æ¸©æš–', 'æ²»æ„ˆ', 'å®‰å¿ƒ', 'ä¸èˆ',\n",
    "    'æ€€å¿µ', 'æ€å¿µ', 'æƒ³å¿µ', 'å°Šé‡', 'ä½“é¢', 'å°Šä¸¥', 'å¥½å¥½å‘Šåˆ«', 'å¿ƒç–¼',\n",
    "    # åœºæ™¯ç›¸å…³\n",
    "    'å® ç‰©æ®¡è‘¬', 'å® ç‰©ç«åŒ–', 'å® ç‰©å®‰è‘¬', 'é€æœ€åä¸€ç¨‹', 'æœ€åçš„å‘Šåˆ«', 'ç”Ÿå‘½ç»ˆç‚¹', 'ä¸´ç»ˆå…³æ€€'\n",
    "}\n",
    "\n",
    "# æ— å…³å…³é”®è¯ï¼ˆå‰”é™¤è§†é¢‘è¯„ä»·ã€é—²èŠç­‰éä¸»é¢˜å†…å®¹ï¼‰\n",
    "IRRELEVANT_KEYWORDS = {\n",
    "    'UPä¸»', 'è§†é¢‘', 'ç”»é¢', 'å‰ªè¾‘', 'é…ä¹', 'BGM', 'å¼¹å¹•', 'è¯„è®º', 'ç‚¹èµ',\n",
    "    'æŠ•å¸', 'æ”¶è—', 'å…³æ³¨', 'è½¬å‘', 'ç›´æ’­', 'æ›´æ–°', 'å‚¬æ›´', 'æ‹–æ›´', 'é¸½å­',\n",
    "    'ä¸»æ’­', 'é¢œå€¼', 'èº«æ', 'æ˜æ˜Ÿ', 'å¤©æ°”', 'å­£èŠ‚', 'ç¾é£Ÿ', 'æ¸¸æˆ', 'è¿½å‰§',\n",
    "    'å­¦ä¹ ', 'å·¥ä½œ', 'è€ƒè¯•', 'æ”¾å‡', 'å¼€å­¦', 'ç”µå½±', 'ç”µè§†å‰§', 'ç»¼è‰º'\n",
    "}\n",
    "\n",
    "# ===================== 2. å…³é”®å·¥å…·ï¼šè‡ªåŠ¨è¯†åˆ«å¼¹å¹•åˆ—åï¼ˆè§£å†³KeyErrorï¼‰ =====================\n",
    "def auto_detect_comment_column(df):\n",
    "    \"\"\"\n",
    "    è‡ªåŠ¨è¯†åˆ«å¼¹å¹•å†…å®¹åˆ—ï¼Œé€‚é…ä¸åŒæ–‡ä»¶æ ¼å¼\n",
    "    æ”¯æŒåˆ—åï¼šå†…å®¹ã€å¼¹å¹•å†…å®¹ã€commentã€danmuã€å¼¹å¹•ã€textç­‰\n",
    "    \"\"\"\n",
    "    # å¸¸è§å¼¹å¹•åˆ—ååº“ï¼ˆå«ä¸­è‹±æ–‡ã€å¤§å°å†™é€‚é…ï¼‰\n",
    "    target_patterns = ['å†…å®¹', 'å¼¹å¹•', 'comment', 'danmu', 'text', 'ç•™è¨€']\n",
    "    \n",
    "    # éå†åˆ—ååŒ¹é…\n",
    "    for col in df.columns:\n",
    "        col_lower = str(col).strip().lower()\n",
    "        for pattern in target_patterns:\n",
    "            if pattern in str(col) or pattern.lower() in col_lower:\n",
    "                print(f\"âœ… è‡ªåŠ¨è¯†åˆ«å¼¹å¹•åˆ—ï¼šã€{col}ã€‘\")\n",
    "                return col\n",
    "    \n",
    "    # æ‰‹åŠ¨é€‰æ‹©ï¼ˆè‹¥è‡ªåŠ¨è¯†åˆ«å¤±è´¥ï¼‰\n",
    "    print(f\"\\nâš ï¸  æœªè‡ªåŠ¨åŒ¹é…å¼¹å¹•åˆ—ï¼Œå½“å‰æ–‡ä»¶åˆ—åï¼š\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"   {i}. {col}\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"è¯·è¾“å…¥å¼¹å¹•å†…å®¹åˆ—å¯¹åº”çš„åºå·ï¼ˆå¦‚1ï¼‰ï¼š\"))\n",
    "            selected_col = df.columns[choice-1]\n",
    "            print(f\"âœ… æ‚¨é€‰æ‹©çš„å¼¹å¹•åˆ—ï¼šã€{selected_col}ã€‘\")\n",
    "            return selected_col\n",
    "        except (ValueError, IndexError):\n",
    "            print(f\"âŒ è¾“å…¥æ— æ•ˆï¼Œè¯·é‡æ–°è¾“å…¥æ­£ç¡®åºå·ï¼\")\n",
    "\n",
    "# ===================== 3. å®‰å…¨ä¿å­˜ï¼šé¿å…æƒé™é”™è¯¯ä¸æ–‡ä»¶è¦†ç›– =====================\n",
    "def safe_save_excel(df, output_path):\n",
    "    \"\"\"\n",
    "    è‡ªåŠ¨å¤„ç†ï¼š\n",
    "    1. åˆ›å»ºä¸å­˜åœ¨çš„æ–‡ä»¶å¤¹\n",
    "    2. é‡å‘½åå·²å­˜åœ¨çš„æ–‡ä»¶ï¼ˆåŠ æ—¶é—´æˆ³ï¼‰\n",
    "    3. é‡è¯•æ–‡ä»¶å ç”¨é—®é¢˜\n",
    "    \"\"\"\n",
    "    # 1. åˆ›å»ºæ–‡ä»¶å¤¹\n",
    "    folder_path = os.path.dirname(output_path)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"ğŸ“‚ è‡ªåŠ¨åˆ›å»ºæ–‡ä»¶å¤¹ï¼š{folder_path}\")\n",
    "    \n",
    "    # 2. å¤„ç†æ–‡ä»¶é‡å\n",
    "    if os.path.exists(output_path):\n",
    "        file_name, ext = os.path.splitext(output_path)\n",
    "        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")  # ç²¾ç¡®åˆ°ç§’ï¼Œé¿å…é‡å¤\n",
    "        output_path = f\"{file_name}_{timestamp}{ext}\"\n",
    "        print(f\"âš ï¸  ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œé‡å‘½åä¸ºï¼š{os.path.basename(output_path)}\")\n",
    "    \n",
    "    # 3. 3æ¬¡é‡è¯•ä¿å­˜ï¼ˆåº”å¯¹æ–‡ä»¶å ç”¨ï¼‰\n",
    "    for retry in range(3):\n",
    "        try:\n",
    "            df.to_excel(output_path, index=False, engine='openpyxl')\n",
    "            return output_path\n",
    "        except PermissionError:\n",
    "            if retry == 2:\n",
    "                print(f\"âŒ ä¿å­˜å¤±è´¥ï¼šæ–‡ä»¶è¢«å ç”¨ï¼Œè¯·å…³é—­ç›¸å…³Excelçª—å£åé‡è¯•ï¼\")\n",
    "                return None\n",
    "            print(f\"âš ï¸ æ–‡ä»¶è¢«å ç”¨ï¼Œ{3-retry}ç§’åé‡è¯•...\")\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ä¿å­˜å¤±è´¥ï¼š{str(e)}\")\n",
    "            return None\n",
    "\n",
    "# ===================== 4. æ–‡æœ¬æ¸…æ´—ï¼šå»é™¤å¹²æ‰°ï¼Œä¿ç•™æƒ…æ„Ÿä¿¡æ¯ =====================\n",
    "def clean_danmu_text(text):\n",
    "    \"\"\"\n",
    "    å•æ¡å¼¹å¹•æ¸…æ´—é€»è¾‘ï¼š\n",
    "    1. åŸºç¡€æ ¼å¼æ¸…ç†\n",
    "    2. ç‰¹æ®Šç¬¦å·è¿‡æ»¤\n",
    "    3. æ— æ„ä¹‰æ–‡æœ¬å‰”é™¤\n",
    "    4. é‡å¤å­—ç¬¦ç®€åŒ–\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or str(text).strip() == '':\n",
    "        return ''\n",
    "    \n",
    "    # 1. åŸºç¡€æ ¼å¼æ¸…ç†\n",
    "    text = str(text).strip()\n",
    "    text = re.sub(r'[\\n\\r\\t]', '', text)  # å»é™¤æ¢è¡Œ/åˆ¶è¡¨ç¬¦\n",
    "    text = re.sub(r'\\s+', ' ', text)      # å¤šä¸ªç©ºæ ¼â†’å•ä¸ªç©ºæ ¼\n",
    "    \n",
    "    # 2. ç‰¹æ®Šç¬¦å·è¿‡æ»¤ï¼ˆä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€æƒ…æ„Ÿæ ‡ç‚¹ï¼‰\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5a-zA-Z0-9ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š\"\"''ï¼ˆï¼‰ã€ã€‘ã€Â·â€¦â€”\\s]', '', text)\n",
    "    \n",
    "    # 3. å‰”é™¤æ— æ„ä¹‰æ–‡æœ¬ï¼ˆé•¿åº¦<2ä¸”éæƒ…æ„Ÿè¯ï¼‰\n",
    "    meaningless_chars = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'å’Œ', 'ä¸', 'åŠ', 'ç­‰', 'å•Š', 'å‘€', 'å‘¢', 'å“¦', 'å§'}\n",
    "    if len(text) < 2 or (len(text) == 1 and text in meaningless_chars):\n",
    "        return ''\n",
    "    \n",
    "    # 4. ç®€åŒ–é‡å¤å­—ç¬¦ï¼ˆå¦‚\"å‘œå‘œå‘œå‘œ\"â†’\"å‘œå‘œ\"ï¼Œä¿ç•™æƒ…æ„Ÿå¼ºåº¦ï¼‰\n",
    "    text = re.sub(r'(.)\\1{3,}', r'\\1\\1', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# ===================== 5. ä¸»é¢˜è¿‡æ»¤ï¼šä»…ä¿ç•™å® ç‰©æ®¡è‘¬ç›¸å…³å¼¹å¹• =====================\n",
    "def is_pet_funeral_related(text):\n",
    "    \"\"\"\n",
    "    ä¸‰å±‚åˆ¤æ–­é€»è¾‘ï¼Œç¡®ä¿ä¸»é¢˜ç²¾å‡†ï¼š\n",
    "    1. æ­£å‘åŒ¹é…ï¼šå«ç›¸å…³å…³é”®è¯â†’ä¿ç•™\n",
    "    2. åå‘æ’é™¤ï¼šå«æ— å…³å…³é”®è¯â†’å‰”é™¤\n",
    "    3. è¡¥å……åŒ¹é…ï¼šæƒ…æ„Ÿ+åœºæ™¯â†’ä¿ç•™\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return False\n",
    "    \n",
    "    # 1. æ­£å‘åŒ¹é…ï¼šå«å® ç‰©æ®¡è‘¬ç›¸å…³å…³é”®è¯\n",
    "    for kw in RELEVANT_KEYWORDS:\n",
    "        if kw in text:\n",
    "            return True\n",
    "    \n",
    "    # 2. åå‘æ’é™¤ï¼šå«æ— å…³å…³é”®è¯\n",
    "    for kw in IRRELEVANT_KEYWORDS:\n",
    "        if kw in text:\n",
    "            return False\n",
    "    \n",
    "    # 3. è¡¥å……åŒ¹é…ï¼šæ— æ˜ç¡®å…³é”®è¯ä½†ç¬¦åˆ\"æƒ…æ„Ÿ+å® ç‰©/ç¦»åˆ«\"åœºæ™¯\n",
    "    emotion_words = {'æ³ªç›®', 'å“­äº†', 'éš¾è¿‡', 'å¿ƒç–¼', 'æ„ŸåŠ¨', 'ä¸èˆ', 'æ€€å¿µ', 'å¿ƒç–¼'}\n",
    "    pet_leave_words = {'çŒ«', 'ç‹—', 'å® ç‰©', 'æ¯›å­©å­', 'ç¦»å¼€', 'èµ°äº†', 'é€å»', 'å‘Šåˆ«', 'å®‰æ¯'}\n",
    "    if any(word in text for word in emotion_words) and any(word in text for word in pet_leave_words):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# ===================== 6. å®Œæ•´æ¸…æ´—æµç¨‹ï¼šä¸€é”®æ‰§è¡Œ =====================\n",
    "def full_pet_funeral_clean(input_path, output_path):\n",
    "    \"\"\"\n",
    "    å®Œæ•´æµç¨‹ï¼šè¯»å–â†’è¯†åˆ«åˆ—â†’æ¸…æ´—â†’è¿‡æ»¤â†’ä¿å­˜â†’æŠ¥å‘Š\n",
    "    è¿”å›ï¼šæ¸…æ´—åDataFrameã€ä¿å­˜è·¯å¾„\n",
    "    \"\"\"\n",
    "    # æ­¥éª¤1ï¼šè¯»å–åŸå§‹æ•°æ®\n",
    "    try:\n",
    "        df_original = pd.read_excel(input_path, engine='openpyxl')\n",
    "        print(f\"âœ… æˆåŠŸè¯»å–æ•°æ®ï¼šå…±{len(df_original)}æ¡è®°å½•\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ•°æ®è¯»å–å¤±è´¥ï¼š{str(e)}\")\n",
    "        print(\"è¯·æ£€æŸ¥ï¼š1.æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡® 2.æ˜¯å¦å®‰è£…openpyxlï¼ˆæ‰§è¡Œï¼špip install openpyxlï¼‰\")\n",
    "        return None, None\n",
    "    \n",
    "    # æ­¥éª¤2ï¼šè‡ªåŠ¨è¯†åˆ«å¼¹å¹•åˆ—\n",
    "    comment_col = auto_detect_comment_column(df_original)\n",
    "    \n",
    "    # æ­¥éª¤3ï¼šæ–‡æœ¬æ¸…æ´—\n",
    "    print(f\"\\nğŸ”§ å¼€å§‹æ–‡æœ¬æ¸…æ´—...\")\n",
    "    df_original['æ¸…æ´—åå†…å®¹'] = df_original[comment_col].apply(clean_danmu_text)\n",
    "    df_cleaned = df_original[df_original['æ¸…æ´—åå†…å®¹'] != ''].copy()  # å‰”é™¤æ— æ•ˆæ–‡æœ¬\n",
    "    invalid_count = len(df_original) - len(df_cleaned)\n",
    "    print(f\"   æ¸…æ´—å®Œæˆï¼šå‰”é™¤æ— æ•ˆæ–‡æœ¬{invalid_count}æ¡ï¼Œå‰©ä½™{len(df_cleaned)}æ¡æœ‰æ•ˆæ–‡æœ¬\")\n",
    "    \n",
    "    # æ­¥éª¤4ï¼šä¸»é¢˜è¿‡æ»¤ï¼ˆæ ¸å¿ƒï¼‰\n",
    "    print(f\"\\nğŸ¯ å¼€å§‹å® ç‰©æ®¡è‘¬ä¸»é¢˜è¿‡æ»¤...\")\n",
    "    df_cleaned['æ˜¯å¦ç›¸å…³'] = df_cleaned['æ¸…æ´—åå†…å®¹'].apply(is_pet_funeral_related)\n",
    "    df_final = df_cleaned[df_cleaned['æ˜¯å¦ç›¸å…³'] == True].copy().reset_index(drop=True)\n",
    "    irrelevant_count = len(df_cleaned) - len(df_final)\n",
    "    print(f\"   è¿‡æ»¤å®Œæˆï¼šå‰”é™¤æ— å…³å¼¹å¹•{irrelevant_count}æ¡ï¼Œä¿ç•™{len(df_final)}æ¡ç›¸å…³å¼¹å¹•\")\n",
    "    \n",
    "    # æ­¥éª¤5ï¼šæ·»åŠ åˆ†æè¾…åŠ©åˆ—\n",
    "    df_final['å¼¹å¹•åºå·'] = range(1, len(df_final) + 1)  # å”¯ä¸€åºå·\n",
    "    df_final['æ–‡æœ¬é•¿åº¦'] = df_final['æ¸…æ´—åå†…å®¹'].apply(len)  # æ–‡æœ¬é•¿åº¦ï¼ˆæƒ…æ„Ÿå¼ºåº¦å‚è€ƒï¼‰\n",
    "    \n",
    "    # æ­¥éª¤6ï¼šæ•´ç†è¾“å‡ºæ ¼å¼ï¼ˆç»Ÿä¸€åˆ—åï¼Œä¾¿äºåç»­åˆ†æï¼‰\n",
    "    df_output = df_final.rename(columns={comment_col: 'åŸå§‹å†…å®¹'})  # ç»Ÿä¸€åŸå§‹åˆ—å\n",
    "    df_output = df_output[['å¼¹å¹•åºå·', 'åŸå§‹å†…å®¹', 'æ¸…æ´—åå†…å®¹', 'æ–‡æœ¬é•¿åº¦']].copy()\n",
    "    \n",
    "    # æ­¥éª¤7ï¼šå®‰å…¨ä¿å­˜\n",
    "    save_path = safe_save_excel(df_output, output_path)\n",
    "    if not save_path:\n",
    "        return None, None\n",
    "    \n",
    "    # æ­¥éª¤8ï¼šè¾“å‡ºæ¸…æ´—æŠ¥å‘Š\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"          å® ç‰©æ®¡è‘¬å¼¹å¹•æ¸…æ´—æŠ¥å‘Šï¼ˆBV1iJ4m1G7kJï¼‰\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼š\")\n",
    "    print(f\"   â€¢ åŸå§‹æ•°æ®æ€»é‡ï¼š{len(df_original)}æ¡\")\n",
    "    print(f\"   â€¢ æœ€ç»ˆç›¸å…³æ•°æ®ï¼š{len(df_final)}æ¡\")\n",
    "    print(f\"   â€¢ æ•°æ®ä¿ç•™ç‡ï¼š{round(len(df_final)/len(df_original)*100, 2)}%\")\n",
    "    if len(df_final) > 0:\n",
    "        print(f\"ğŸ“ æ–‡æœ¬ç‰¹å¾ï¼š\")\n",
    "        print(f\"   â€¢ å¹³å‡æ–‡æœ¬é•¿åº¦ï¼š{round(df_final['æ–‡æœ¬é•¿åº¦'].mean(), 2)}å­—ç¬¦\")\n",
    "        print(f\"   â€¢ æœ€é•¿å¼¹å¹•é•¿åº¦ï¼š{df_final['æ–‡æœ¬é•¿åº¦'].max()}å­—ç¬¦\")\n",
    "        print(f\"   â€¢ æœ€çŸ­å¼¹å¹•é•¿åº¦ï¼š{df_final['æ–‡æœ¬é•¿åº¦'].min()}å­—ç¬¦\")\n",
    "    print(f\"\\nğŸ“ è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼š{save_path}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return df_output, save_path\n",
    "\n",
    "# ===================== ä¸»æ‰§è¡Œå…¥å£ =====================\n",
    "if __name__ == \"__main__\":\n",
    "    # ---------------------- æœ¬åœ°è·¯å¾„é…ç½®ï¼ˆè¯·ç¡®è®¤æ˜¯å¦ä¸æ‚¨çš„æ–‡ä»¶ä¸€è‡´ï¼‰ ----------------------\n",
    "    INPUT_FILE = r\"D:\\CITYU COURSES\\5507\\homework\\å¼¹å¹•\\BV1iJ4m1G7kJå¼¹å¹•æ•°æ®.xlsx\"\n",
    "    OUTPUT_FILE = r\"D:\\CITYU COURSES\\5507\\homework\\å¼¹å¹•\\BV1iJ4m1G7kJå¼¹å¹•æ•°æ®_æ¸…æ´—å®Œæˆç‰ˆ.xlsx\"\n",
    "    # -------------------------------------------------------------------------------------\n",
    "    \n",
    "    # æ‰§è¡Œå®Œæ•´æ¸…æ´—\n",
    "    cleaned_data, saved_path = full_pet_funeral_clean(INPUT_FILE, OUTPUT_FILE)\n",
    "    if cleaned_data is not None and saved_path:\n",
    "        print(f\"\\nğŸ‰ æ¸…æ´—ä»»åŠ¡å®Œæˆï¼å¯ç›´æ¥ä½¿ç”¨ã€{os.path.basename(saved_path)}ã€‘åˆ¶ä½œæƒ…æ„Ÿåˆ†æå›¾ï½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d576aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸè¯»å–åŸå§‹æ•°æ®ï¼šå…±1200æ¡å¼¹å¹•è®°å½•\n",
      "âœ… è‡ªåŠ¨è¯†åˆ«å¼¹å¹•åˆ—ï¼šã€å¼¹å¹•å†…å®¹ã€‘\n",
      "\n",
      "ğŸ”§ å¼€å§‹æ‰¹é‡æ–‡æœ¬æ¸…æ´—...\n",
      "   æ–‡æœ¬æ¸…æ´—å®Œæˆï¼šå‰”é™¤æ— æ•ˆæ–‡æœ¬7æ¡ï¼Œå‰©ä½™1193æ¡æœ‰æ•ˆæ–‡æœ¬\n",
      "\n",
      "ğŸ¯ å¼€å§‹å® ç‰©æ®¡è‘¬ä¸»é¢˜è¿‡æ»¤...\n",
      "   ä¸»é¢˜è¿‡æ»¤å®Œæˆï¼šå‰”é™¤æ— å…³å¼¹å¹•722æ¡ï¼Œä¿ç•™471æ¡å® ç‰©æ®¡è‘¬ç›¸å…³å¼¹å¹•\n",
      "\n",
      "============================================================\n",
      "          å® ç‰©æ®¡è‘¬å¼¹å¹•æ¸…æ´—æŠ¥å‘Šï¼ˆBV16Z4y1K7PMï¼‰\n",
      "============================================================\n",
      "ğŸ“Š æ•°æ®è§„æ¨¡ç»Ÿè®¡ï¼š\n",
      "   â€¢ åŸå§‹æ•°æ®æ€»é‡ï¼š1200æ¡\n",
      "   â€¢ æœ€ç»ˆç›¸å…³æ•°æ®ï¼š471æ¡\n",
      "   â€¢ æ•°æ®ä¿ç•™ç‡ï¼š39.25%\n",
      "ğŸ“ æ–‡æœ¬ç‰¹å¾ç»Ÿè®¡ï¼š\n",
      "   â€¢ å¹³å‡æ–‡æœ¬é•¿åº¦ï¼š13.82å­—ç¬¦\n",
      "   â€¢ æœ€é•¿å¼¹å¹•é•¿åº¦ï¼š100å­—ç¬¦\n",
      "   â€¢ æœ€çŸ­å¼¹å¹•é•¿åº¦ï¼š2å­—ç¬¦\n",
      "\n",
      "ğŸ“ æ¸…æ´—åæ–‡ä»¶è·¯å¾„ï¼šD:\\CITYU COURSES\\5507\\homework\\å¼¹å¹•\\BV16Z4y1K7PMå¼¹å¹•æ•°æ®_æ¸…æ´—å®Œæˆç‰ˆ.xlsx\n",
      "============================================================\n",
      "\n",
      "ğŸ‰ æ¸…æ´—ä»»åŠ¡å®Œæˆï¼å¯ç›´æ¥ä½¿ç”¨ã€BV16Z4y1K7PMå¼¹å¹•æ•°æ®_æ¸…æ´—å®Œæˆç‰ˆ.xlsxã€‘åˆ¶ä½œå® ç‰©æ®¡è‘¬æƒ…æ„Ÿåˆ†æå›¾ï½\n"
     ]
    }
   ],
   "source": [
    "# å® ç‰©æ®¡è‘¬Bç«™å¼¹å¹•æ¸…æ´—ä»£ç ï¼ˆé€‚é…BV16Z4y1K7PMæ–‡ä»¶ï¼‰\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===================== 1. æ ¸å¿ƒé…ç½®ï¼šå® ç‰©æ®¡è‘¬ä¸»é¢˜å…³é”®è¯åº“ =====================\n",
    "# ç›¸å…³å…³é”®è¯ï¼ˆè¦†ç›–å® ç‰©ç±»å‹ã€æ®¡è‘¬åœºæ™¯ã€æƒ…æ„Ÿè¡¨è¾¾ï¼Œç¡®ä¿ä¸»é¢˜ç²¾å‡†ï¼‰\n",
    "RELEVANT_KEYWORDS = {\n",
    "    # å® ç‰©ç±»å‹ï¼ˆæ‰©å……å¸¸è§å® ç‰©ï¼‰\n",
    "    'çŒ«', 'å–µ', 'çŒ«å’ª', 'å°çŒ«', 'çŒ«ä¸»å­', 'ç‹—', 'æ±ª', 'ç‹—ç‹—', 'å°ç‹—', 'å® ç‰©',\n",
    "    'æ¯›å­©å­', 'ä¸»å­', 'å°å®¶ä¼™', 'å°åŠ¨ç‰©', 'é¾Ÿ', 'ä¹Œé¾Ÿ', 'ä»“é¼ ', 'å…”å­', 'é¾™çŒ«',\n",
    "    'é¹¦é¹‰', 'é¸Ÿ', 'é±¼', 'è·å…°çŒª', 'è±šé¼ ', 'ä»“é¼ ', 'èœœè¢‹é¼¯', 'èŠ±æé¼ ',\n",
    "    # æ®¡è‘¬æ ¸å¿ƒåœºæ™¯\n",
    "    'æ®¡è‘¬', 'è‘¬ç¤¼', 'å®‰è‘¬', 'ç«åŒ–', 'å‘Šåˆ«', 'é€è¡Œ', 'å®‰æ¯', 'é•¿çœ ', 'ç¦»ä¸–', 'å»ä¸–',\n",
    "    'é€å»', 'ç¦»å¼€', 'èµ°äº†', 'å¾€ç”Ÿ', 'åäº‹', 'å‘Šåˆ«ä»ªå¼', 'éª¨ç°', 'å¢“ç¢‘', 'ä¸‹è‘¬',\n",
    "    'å® ç‰©æ®¡è‘¬', 'å® ç‰©ç«åŒ–', 'å® ç‰©å®‰è‘¬', 'å® ç‰©è‘¬ç¤¼',\n",
    "    # æƒ…æ„Ÿè¡¨è¾¾ï¼ˆé€‚é…å® ç‰©æ®¡è‘¬æƒ…æ„Ÿå€¾å‘ï¼‰\n",
    "    'æ³ªç›®', 'å“­äº†', 'éš¾è¿‡', 'å¿ƒç–¼', 'æ„ŸåŠ¨', 'æ¸©æš–', 'æ²»æ„ˆ', 'å®‰å¿ƒ', 'ä¸èˆ',\n",
    "    'æ€€å¿µ', 'æ€å¿µ', 'æƒ³å¿µ', 'å°Šé‡', 'ä½“é¢', 'å°Šä¸¥', 'å¥½å¥½å‘Šåˆ«', 'å¿ƒç–¼', 'å¿ƒç¢',\n",
    "    # ç›¸å…³åœºæ™¯è¡¥å……\n",
    "    'é€æœ€åä¸€ç¨‹', 'æœ€åçš„å‘Šåˆ«', 'ç”Ÿå‘½ç»ˆç‚¹', 'ä¸´ç»ˆå…³æ€€', 'çºªå¿µ', 'ç¼…æ€€', 'æ‚¼å¿µ'\n",
    "}\n",
    "\n",
    "# æ— å…³å…³é”®è¯ï¼ˆå‰”é™¤è§†é¢‘è¯„ä»·ã€é—²èŠç­‰éä¸»é¢˜å†…å®¹ï¼‰\n",
    "IRRELEVANT_KEYWORDS = {\n",
    "    'UPä¸»', 'è§†é¢‘', 'ç”»é¢', 'å‰ªè¾‘', 'é…ä¹', 'BGM', 'å¼¹å¹•', 'è¯„è®º', 'ç‚¹èµ',\n",
    "    'æŠ•å¸', 'æ”¶è—', 'å…³æ³¨', 'è½¬å‘', 'ç›´æ’­', 'æ›´æ–°', 'å‚¬æ›´', 'æ‹–æ›´', 'é¸½å­',\n",
    "    'ä¸»æ’­', 'é¢œå€¼', 'èº«æ', 'æ˜æ˜Ÿ', 'å¤©æ°”', 'å­£èŠ‚', 'ç¾é£Ÿ', 'æ¸¸æˆ', 'è¿½å‰§',\n",
    "    'å­¦ä¹ ', 'å·¥ä½œ', 'è€ƒè¯•', 'æ”¾å‡', 'å¼€å­¦', 'ç”µå½±', 'ç”µè§†å‰§', 'ç»¼è‰º', 'åŠ¨æ¼«',\n",
    "    'æ‰“å¡', 'ç­¾åˆ°', 'æ²™å‘', 'å‰æ’', 'å›´è§‚', 'è·¯è¿‡', 'é£˜è¿‡'\n",
    "}\n",
    "\n",
    "# ===================== 2. å…³é”®å·¥å…·ï¼šè‡ªåŠ¨è¯†åˆ«å¼¹å¹•åˆ—åï¼ˆè§£å†³KeyErrorï¼‰ =====================\n",
    "def auto_detect_comment_col(df):\n",
    "    \"\"\"\n",
    "    è‡ªåŠ¨è¯†åˆ«å¼¹å¹•å†…å®¹åˆ—ï¼Œé€‚é…ä¸åŒæ–‡ä»¶æ ¼å¼ï¼š\n",
    "    - æ”¯æŒåˆ—åï¼šå†…å®¹ã€å¼¹å¹•å†…å®¹ã€commentã€danmuã€å¼¹å¹•ã€textç­‰\n",
    "    - è‡ªåŠ¨å®¹é”™ï¼Œè¯†åˆ«å¤±è´¥æ—¶å¼•å¯¼æ‰‹åŠ¨é€‰æ‹©\n",
    "    \"\"\"\n",
    "    # å¸¸è§å¼¹å¹•åˆ—ååŒ¹é…è§„åˆ™\n",
    "    target_col_patterns = ['å†…å®¹', 'å¼¹å¹•', 'comment', 'danmu', 'text', 'ç•™è¨€', 'ä¿¡æ¯']\n",
    "    \n",
    "    # éå†åˆ—ååŒ¹é…ï¼ˆä¸åŒºåˆ†å¤§å°å†™ã€ç©ºæ ¼ï¼‰\n",
    "    for col in df.columns:\n",
    "        col_clean = str(col).strip().lower()\n",
    "        for pattern in target_col_patterns:\n",
    "            if pattern in str(col) or pattern.lower() in col_clean:\n",
    "                print(f\"âœ… è‡ªåŠ¨è¯†åˆ«å¼¹å¹•åˆ—ï¼šã€{col}ã€‘\")\n",
    "                return col\n",
    "    \n",
    "    # æ‰‹åŠ¨é€‰æ‹©æµç¨‹ï¼ˆè‡ªåŠ¨è¯†åˆ«å¤±è´¥æ—¶ï¼‰\n",
    "    print(f\"\\nâš ï¸  æœªè‡ªåŠ¨åŒ¹é…å¼¹å¹•åˆ—ï¼Œå½“å‰æ–‡ä»¶æ‰€æœ‰åˆ—åï¼š\")\n",
    "    for idx, col in enumerate(df.columns, 1):\n",
    "        print(f\"   {idx}. {col}\")\n",
    "    \n",
    "    # è¾“å…¥éªŒè¯ï¼Œç¡®ä¿é€‰æ‹©æœ‰æ•ˆåˆ—\n",
    "    while True:\n",
    "        try:\n",
    "            user_choice = int(input(\"è¯·è¾“å…¥å¼¹å¹•å†…å®¹æ‰€åœ¨åˆ—çš„åºå·ï¼ˆå¦‚1/2ï¼‰ï¼š\"))\n",
    "            selected_col = df.columns[user_choice - 1]\n",
    "            print(f\"âœ… ç¡®è®¤é€‰æ‹©å¼¹å¹•åˆ—ï¼šã€{selected_col}ã€‘\")\n",
    "            return selected_col\n",
    "        except (ValueError, IndexError):\n",
    "            print(f\"âŒ è¾“å…¥æ— æ•ˆï¼è¯·è¾“å…¥åˆ—åå¯¹åº”çš„æ•°å­—åºå·ï¼ˆå¦‚1å¯¹åº”ç¬¬ä¸€åˆ—ï¼‰\")\n",
    "\n",
    "# ===================== 3. å®‰å…¨ä¿å­˜ï¼šé¿å…æƒé™é”™è¯¯ä¸æ–‡ä»¶è¦†ç›– =====================\n",
    "def safe_save_excel(df, output_path):\n",
    "    \"\"\"\n",
    "    å®‰å…¨ä¿å­˜é€»è¾‘ï¼š\n",
    "    1. è‡ªåŠ¨åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤¹ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰\n",
    "    2. é‡å‘½åå·²å­˜åœ¨æ–‡ä»¶ï¼ˆæ·»åŠ æ—¶é—´æˆ³ï¼Œé¿å…è¦†ç›–ï¼‰\n",
    "    3. 3æ¬¡é‡è¯•æœºåˆ¶ï¼ˆè§£å†³æ–‡ä»¶è¢«å ç”¨é—®é¢˜ï¼‰\n",
    "    \"\"\"\n",
    "    # 1. åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤¹\n",
    "    folder_dir = os.path.dirname(output_path)\n",
    "    if not os.path.exists(folder_dir):\n",
    "        os.makedirs(folder_dir)\n",
    "        print(f\"ğŸ“‚ è‡ªåŠ¨åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤¹ï¼š{folder_dir}\")\n",
    "    \n",
    "    # 2. å¤„ç†æ–‡ä»¶é‡åï¼ˆæ·»åŠ ç²¾ç¡®æ—¶é—´æˆ³ï¼‰\n",
    "    if os.path.exists(output_path):\n",
    "        file_name, file_ext = os.path.splitext(output_path)\n",
    "        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")  # ç²¾ç¡®åˆ°ç§’ï¼Œé¿å…é‡å¤\n",
    "        output_path = f\"{file_name}_{timestamp}{file_ext}\"\n",
    "        print(f\"âš ï¸  ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œè‡ªåŠ¨é‡å‘½åä¸ºï¼š{os.path.basename(output_path)}\")\n",
    "    \n",
    "    # 3. é‡è¯•ä¿å­˜ï¼ˆåº”å¯¹æ–‡ä»¶å ç”¨ï¼‰\n",
    "    for retry_cnt in range(3):\n",
    "        try:\n",
    "            df.to_excel(output_path, index=False, engine='openpyxl')\n",
    "            return output_path\n",
    "        except PermissionError:\n",
    "            if retry_cnt == 2:\n",
    "                print(f\"âŒ ä¿å­˜å¤±è´¥ï¼šæ–‡ä»¶è¢«å ç”¨ï¼Œè¯·å…³é—­ç›¸å…³Excelçª—å£åé‡è¯•ï¼\")\n",
    "                return None\n",
    "            print(f\"âš ï¸ æ–‡ä»¶è¢«å ç”¨ï¼Œ{3 - retry_cnt}ç§’åé‡è¯•...\")\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ä¿å­˜å¤±è´¥ï¼š{str(e)}\")\n",
    "            return None\n",
    "\n",
    "# ===================== 4. æ–‡æœ¬æ¸…æ´—ï¼šå»é™¤å¹²æ‰°ï¼Œä¿ç•™æƒ…æ„Ÿæ ¸å¿ƒä¿¡æ¯ =====================\n",
    "def clean_danmu_text(text):\n",
    "    \"\"\"\n",
    "    å•æ¡å¼¹å¹•æ¸…æ´—é€»è¾‘ï¼ˆé€‚é…æƒ…æ„Ÿåˆ†æéœ€æ±‚ï¼‰ï¼š\n",
    "    1. åŸºç¡€æ ¼å¼æ¸…ç† â†’ 2. ç‰¹æ®Šç¬¦å·è¿‡æ»¤ â†’ 3. æ— æ„ä¹‰æ–‡æœ¬å‰”é™¤ â†’ 4. é‡å¤å­—ç¬¦ç®€åŒ–\n",
    "    \"\"\"\n",
    "    # å¤„ç†ç©ºå€¼/éå­—ç¬¦ä¸²ç±»å‹\n",
    "    if pd.isna(text) or not isinstance(text, (str, int, float)):\n",
    "        return ''\n",
    "    \n",
    "    # 1. åŸºç¡€æ ¼å¼æ¸…ç†\n",
    "    text = str(text).strip()\n",
    "    text = re.sub(r'[\\n\\r\\t]', '', text)  # å»é™¤æ¢è¡Œã€å›è½¦ã€åˆ¶è¡¨ç¬¦\n",
    "    text = re.sub(r'\\s+', ' ', text)      # å¤šä¸ªç©ºæ ¼â†’å•ä¸ªç©ºæ ¼ï¼ˆä¿ç•™æƒ…æ„Ÿæ–­å¥ï¼‰\n",
    "    \n",
    "    # 2. ç‰¹æ®Šç¬¦å·è¿‡æ»¤ï¼ˆä»…ä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€æƒ…æ„Ÿç›¸å…³æ ‡ç‚¹ï¼‰\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5a-zA-Z0-9ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š\"\"''ï¼ˆï¼‰ã€ã€‘ã€Â·â€¦â€”\\s]', '', text)\n",
    "    \n",
    "    # 3. å‰”é™¤æ— æ„ä¹‰æ–‡æœ¬ï¼ˆé¿å…å¹²æ‰°æƒ…æ„Ÿåˆ†æï¼‰\n",
    "    meaningless_filter = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'å’Œ', 'ä¸', 'åŠ', 'ç­‰', 'å•Š', 'å‘€', 'å‘¢', 'å“¦', 'å§', 'å‘€'}\n",
    "    if len(text) < 2 or (len(text) == 1 and text in meaningless_filter):\n",
    "        return ''\n",
    "    \n",
    "    # 4. ç®€åŒ–é‡å¤å­—ç¬¦ï¼ˆä¿ç•™æƒ…æ„Ÿå¼ºåº¦ï¼Œé¿å…å†—ä½™ï¼‰\n",
    "    text = re.sub(r'(.)\\1{3,}', r'\\1\\1', text)  # å¦‚\"å‘œå‘œå‘œå‘œ\"â†’\"å‘œå‘œ\"ï¼Œ\"éš¾è¿‡éš¾è¿‡éš¾è¿‡\"â†’\"éš¾è¿‡éš¾è¿‡\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "# ===================== 5. ä¸»é¢˜è¿‡æ»¤ï¼šä»…ä¿ç•™å® ç‰©æ®¡è‘¬ç›¸å…³å¼¹å¹• =====================\n",
    "def is_pet_funeral_related(text):\n",
    "    \"\"\"\n",
    "    ä¸‰å±‚ä¸»é¢˜åˆ¤æ–­é€»è¾‘ï¼ˆç¡®ä¿ç²¾å‡†åº¦ï¼‰ï¼š\n",
    "    1. æ­£å‘åŒ¹é…ï¼šå«ç›¸å…³å…³é”®è¯ â†’ ä¿ç•™\n",
    "    2. åå‘æ’é™¤ï¼šå«æ— å…³å…³é”®è¯ â†’ å‰”é™¤\n",
    "    3. è¡¥å……åŒ¹é…ï¼šæƒ…æ„Ÿ+å® ç‰©/ç¦»åˆ«åœºæ™¯ â†’ ä¿ç•™\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return False\n",
    "    \n",
    "    # 1. æ­£å‘åŒ¹é…ï¼šåŒ…å«å® ç‰©æ®¡è‘¬ç›¸å…³å…³é”®è¯\n",
    "    for relevant_kw in RELEVANT_KEYWORDS:\n",
    "        if relevant_kw in text:\n",
    "            return True\n",
    "    \n",
    "    # 2. åå‘æ’é™¤ï¼šåŒ…å«æ— å…³å…³é”®è¯ï¼ˆä¼˜å…ˆå‰”é™¤ï¼Œå‡å°‘è¯¯åˆ¤ï¼‰\n",
    "    for irrelevant_kw in IRRELEVANT_KEYWORDS:\n",
    "        if irrelevant_kw in text:\n",
    "            return False\n",
    "    \n",
    "    # 3. è¡¥å……åŒ¹é…ï¼šæ— æ˜ç¡®å…³é”®è¯ä½†ç¬¦åˆ\"æƒ…æ„Ÿ+å® ç‰©/ç¦»åˆ«\"åœºæ™¯ï¼ˆé¿å…æ¼åˆ¤ï¼‰\n",
    "    emotion_keywords = {'æ³ªç›®', 'å“­äº†', 'éš¾è¿‡', 'å¿ƒç–¼', 'æ„ŸåŠ¨', 'ä¸èˆ', 'æ€€å¿µ', 'å¿ƒç¢', 'ä½“é¢'}\n",
    "    pet_leave_keywords = {'çŒ«', 'ç‹—', 'å® ç‰©', 'æ¯›å­©å­', 'ç¦»å¼€', 'èµ°äº†', 'é€å»', 'å‘Šåˆ«', 'å®‰æ¯'}\n",
    "    if any(emotion_kw in text for emotion_kw in emotion_keywords) and \\\n",
    "       any(pet_leave_kw in text for pet_leave_kw in pet_leave_keywords):\n",
    "        return True\n",
    "    \n",
    "    # å…¶ä»–æƒ…å†µï¼šåˆ¤å®šä¸ºæ— å…³\n",
    "    return False\n",
    "\n",
    "# ===================== 6. å®Œæ•´æ¸…æ´—æµç¨‹ï¼šä¸€é”®æ‰§è¡Œï¼ˆè¯»å–â†’æ¸…æ´—â†’è¿‡æ»¤â†’ä¿å­˜ï¼‰ =====================\n",
    "def full_pet_funeral_clean(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    å®Œæ•´æ¸…æ´—æµç¨‹ï¼Œè¿”å›æ¸…æ´—åæ•°æ®ä¸ä¿å­˜è·¯å¾„ï¼š\n",
    "    Step1ï¼šè¯»å–åŸå§‹æ•°æ® â†’ Step2ï¼šè¯†åˆ«å¼¹å¹•åˆ— â†’ Step3ï¼šæ–‡æœ¬æ¸…æ´— â†’ Step4ï¼šä¸»é¢˜è¿‡æ»¤ â†’ Step5ï¼šå®‰å…¨ä¿å­˜ â†’ Step6ï¼šè¾“å‡ºæŠ¥å‘Š\n",
    "    \"\"\"\n",
    "    # Step1ï¼šè¯»å–åŸå§‹æ•°æ®\n",
    "    try:\n",
    "        df_original = pd.read_excel(input_file_path, engine='openpyxl')\n",
    "        print(f\"âœ… æˆåŠŸè¯»å–åŸå§‹æ•°æ®ï¼šå…±{len(df_original)}æ¡å¼¹å¹•è®°å½•\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åŸå§‹æ•°æ®è¯»å–å¤±è´¥ï¼š{str(e)}\")\n",
    "        print(\"è¯·æ£€æŸ¥ï¼š1.æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡® 2.æ˜¯å¦å®‰è£…openpyxlï¼ˆæ‰§è¡Œå‘½ä»¤ï¼špip install openpyxlï¼‰\")\n",
    "        return None, None\n",
    "    \n",
    "    # Step2ï¼šè‡ªåŠ¨è¯†åˆ«å¼¹å¹•åˆ—\n",
    "    comment_col = auto_detect_comment_col(df_original)\n",
    "    \n",
    "    # Step3ï¼šæ–‡æœ¬æ¸…æ´—ï¼ˆæ‰¹é‡å¤„ç†ï¼‰\n",
    "    print(f\"\\nğŸ”§ å¼€å§‹æ‰¹é‡æ–‡æœ¬æ¸…æ´—...\")\n",
    "    df_original['æ¸…æ´—åå†…å®¹'] = df_original[comment_col].apply(clean_danmu_text)\n",
    "    # å‰”é™¤æ¸…æ´—åä¸ºç©ºçš„æ— æ•ˆæ•°æ®\n",
    "    df_cleaned_text = df_original[df_original['æ¸…æ´—åå†…å®¹'] != ''].copy()\n",
    "    invalid_text_count = len(df_original) - len(df_cleaned_text)\n",
    "    print(f\"   æ–‡æœ¬æ¸…æ´—å®Œæˆï¼šå‰”é™¤æ— æ•ˆæ–‡æœ¬{invalid_text_count}æ¡ï¼Œå‰©ä½™{len(df_cleaned_text)}æ¡æœ‰æ•ˆæ–‡æœ¬\")\n",
    "    \n",
    "    # Step4ï¼šä¸»é¢˜è¿‡æ»¤ï¼ˆæ ¸å¿ƒæ­¥éª¤ï¼Œèšç„¦å® ç‰©æ®¡è‘¬ï¼‰\n",
    "    print(f\"\\nğŸ¯ å¼€å§‹å® ç‰©æ®¡è‘¬ä¸»é¢˜è¿‡æ»¤...\")\n",
    "    df_cleaned_text['æ˜¯å¦ç›¸å…³'] = df_cleaned_text['æ¸…æ´—åå†…å®¹'].apply(is_pet_funeral_related)\n",
    "    # ä¿ç•™ä»…ç›¸å…³çš„æ•°æ®\n",
    "    df_final = df_cleaned_text[df_cleaned_text['æ˜¯å¦ç›¸å…³'] == True].copy().reset_index(drop=True)\n",
    "    irrelevant_count = len(df_cleaned_text) - len(df_final)\n",
    "    print(f\"   ä¸»é¢˜è¿‡æ»¤å®Œæˆï¼šå‰”é™¤æ— å…³å¼¹å¹•{irrelevant_count}æ¡ï¼Œä¿ç•™{len(df_final)}æ¡å® ç‰©æ®¡è‘¬ç›¸å…³å¼¹å¹•\")\n",
    "    \n",
    "    # Step5ï¼šæ·»åŠ æƒ…æ„Ÿåˆ†æè¾…åŠ©åˆ—\n",
    "    df_final['å¼¹å¹•åºå·'] = range(1, len(df_final) + 1)  # å”¯ä¸€æ ‡è¯†åºå·\n",
    "    df_final['æ–‡æœ¬é•¿åº¦'] = df_final['æ¸…æ´—åå†…å®¹'].apply(len)  # æ–‡æœ¬é•¿åº¦ï¼ˆè¾…åŠ©æƒ…æ„Ÿå¼ºåº¦åˆ†æï¼‰\n",
    "    \n",
    "    # Step6ï¼šæ•´ç†è¾“å‡ºæ ¼å¼ï¼ˆç»Ÿä¸€åˆ—åï¼Œä¾¿äºåç»­åˆ†æï¼‰\n",
    "    df_output = df_final.rename(columns={comment_col: 'åŸå§‹å†…å®¹'})  # ç»Ÿä¸€åŸå§‹åˆ—å\n",
    "    # ä¿ç•™æ ¸å¿ƒåˆ—ï¼šå¼¹å¹•åºå·ã€åŸå§‹å†…å®¹ã€æ¸…æ´—åå†…å®¹ã€æ–‡æœ¬é•¿åº¦\n",
    "    df_output = df_output[['å¼¹å¹•åºå·', 'åŸå§‹å†…å®¹', 'æ¸…æ´—åå†…å®¹', 'æ–‡æœ¬é•¿åº¦']].copy()\n",
    "    \n",
    "    # Step7ï¼šå®‰å…¨ä¿å­˜æ¸…æ´—åæ•°æ®\n",
    "    saved_file_path = safe_save_excel(df_output, output_file_path)\n",
    "    if not saved_file_path:\n",
    "        return None, None\n",
    "    \n",
    "    # Step8ï¼šè¾“å‡ºæ¸…æ´—æŠ¥å‘Šï¼ˆå…³é”®ç»Ÿè®¡ä¿¡æ¯ï¼‰\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"          å® ç‰©æ®¡è‘¬å¼¹å¹•æ¸…æ´—æŠ¥å‘Šï¼ˆBV16Z4y1K7PMï¼‰\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ğŸ“Š æ•°æ®è§„æ¨¡ç»Ÿè®¡ï¼š\")\n",
    "    print(f\"   â€¢ åŸå§‹æ•°æ®æ€»é‡ï¼š{len(df_original)}æ¡\")\n",
    "    print(f\"   â€¢ æœ€ç»ˆç›¸å…³æ•°æ®ï¼š{len(df_final)}æ¡\")\n",
    "    print(f\"   â€¢ æ•°æ®ä¿ç•™ç‡ï¼š{round(len(df_final)/len(df_original)*100, 2)}%\")\n",
    "    if len(df_final) > 0:\n",
    "        print(f\"ğŸ“ æ–‡æœ¬ç‰¹å¾ç»Ÿè®¡ï¼š\")\n",
    "        print(f\"   â€¢ å¹³å‡æ–‡æœ¬é•¿åº¦ï¼š{round(df_final['æ–‡æœ¬é•¿åº¦'].mean(), 2)}å­—ç¬¦\")\n",
    "        print(f\"   â€¢ æœ€é•¿å¼¹å¹•é•¿åº¦ï¼š{df_final['æ–‡æœ¬é•¿åº¦'].max()}å­—ç¬¦\")\n",
    "        print(f\"   â€¢ æœ€çŸ­å¼¹å¹•é•¿åº¦ï¼š{df_final['æ–‡æœ¬é•¿åº¦'].min()}å­—ç¬¦\")\n",
    "    print(f\"\\nğŸ“ æ¸…æ´—åæ–‡ä»¶è·¯å¾„ï¼š{saved_file_path}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return df_output, saved_file_path\n",
    "\n",
    "# ===================== ä¸»æ‰§è¡Œå…¥å£ï¼ˆç›´æ¥è¿è¡Œï¼‰ =====================\n",
    "if __name__ == \"__main__\":\n",
    "    # ---------------------- æœ¬åœ°è·¯å¾„é…ç½®ï¼ˆè¯·ç¡®è®¤ä¸æ‚¨çš„æ–‡ä»¶ä¸€è‡´ï¼‰ ----------------------\n",
    "    INPUT_FILE = r\"D:\\CITYU COURSES\\5507\\homework\\å¼¹å¹•\\BV16Z4y1K7PMå¼¹å¹•æ•°æ®.xlsx\"\n",
    "    OUTPUT_FILE = r\"D:\\CITYU COURSES\\5507\\homework\\å¼¹å¹•\\BV16Z4y1K7PMå¼¹å¹•æ•°æ®_æ¸…æ´—å®Œæˆç‰ˆ.xlsx\"\n",
    "    # -------------------------------------------------------------------------------------\n",
    "    \n",
    "    # æ‰§è¡Œå®Œæ•´æ¸…æ´—æµç¨‹\n",
    "    cleaned_data, saved_path = full_pet_funeral_clean(INPUT_FILE, OUTPUT_FILE)\n",
    "    if cleaned_data is not None and saved_path:\n",
    "        print(f\"\\nğŸ‰ æ¸…æ´—ä»»åŠ¡å®Œæˆï¼å¯ç›´æ¥ä½¿ç”¨ã€{os.path.basename(saved_path)}ã€‘åˆ¶ä½œå® ç‰©æ®¡è‘¬æƒ…æ„Ÿåˆ†æå›¾ï½\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
