{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a135bfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ğŸ“Š åŸå§‹æ•°æ®æ¦‚å†µï¼šæ€»è¡Œæ•°=173ï¼Œå­—æ®µ=['page', 'index', 'name', 'link', 'address', 'avg_price', 'comment_num', 'star']\n",
      "==================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ ç­›é€‰å®Œæˆï¼ç›¸å…³å•†å®¶æ€»è¡Œæ•°ï¼š39\n",
      "ğŸ“ ä¿å­˜è·¯å¾„ï¼š/Users/syx/Documents/pythonè„šæœ¬/pet_funeral_shenzhen_cleaned_20251115_001632.xlsx\n",
      "\n",
      "ğŸ“‹ ç›¸å…³å•†å®¶æ•°æ®å®Œæ•´æ€§ç»Ÿè®¡ï¼ˆä¿®å¤åï¼‰ï¼š\n",
      "1. å«'äººå‡ -'/æ— äººå‡çš„å•†å®¶ï¼š11 å®¶\n",
      "2. æ— è¯„åˆ†ï¼ˆå«0.0åˆ†ï¼‰çš„å•†å®¶ï¼š19 å®¶\n",
      "3. åŒæ—¶æœ‰äººå‡+æœ‰è¯„åˆ†çš„å•†å®¶ï¼š9 å®¶\n",
      "\n",
      "ğŸ” æ— è¯„åˆ†å•†å®¶é¢„è§ˆï¼ˆå‰3å®¶ï¼Œè‹¥æœ‰ï¼‰ï¼š\n",
      "                   name avg_price  star address\n",
      "1   æ„ç”Ÿè‡»å® Â·å°Šäº«å® ç‰©å–„ç»ˆæ®¡ä»ª(æ·±åœ³æ¹¾åº—)      äººå‡ -  0.0åˆ†     ç§‘æŠ€å›­\n",
      "2    å¿µå® Â·å® ç‰©å–„ç»ˆæœåŠ¡ä¸­å¿ƒ(é¾™åå¤§æµªåº—)   äººå‡ ï¿¥797  0.0åˆ†      å¤§æµª\n",
      "12    å® æ˜ŸçºªÂ·å® ç‰©å–„ç»ˆæ®¡è‘¬ç«åŒ–(é¾™å²—åº—)   äººå‡ ï¿¥938  0.0åˆ†  ç½—å²—/æ±‚æ°´å±±\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š åŸå§‹è¯„åˆ†å­—æ®µï¼ˆstarï¼‰çš„å”¯ä¸€å€¼ç¤ºä¾‹ï¼š\n",
      "   æ ¼å¼=str, å€¼='4.0åˆ†'\n",
      "   æ ¼å¼=str, å€¼='0.0åˆ†'\n",
      "   æ ¼å¼=str, å€¼='4.5åˆ†'\n",
      "   æ ¼å¼=str, å€¼='5.0åˆ†'\n",
      "   æ ¼å¼=str, å€¼='3.5åˆ†'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---------------------- 1. è¯»å–åŸå§‹æ•°æ® ----------------------\n",
    "raw_file_path = \"/Users/syx/Documents/pythonè„šæœ¬/å¤§ä¼—ç‚¹è¯„-çˆ¬å–ä»£ç /pet_funeral_shenzhen.xlsx\"  # è¯·ç¡®è®¤æ–‡ä»¶è·¯å¾„æ­£ç¡®\n",
    "if not os.path.exists(raw_file_path):\n",
    "    print(f\"âŒ åŸå§‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{raw_file_path}\")\n",
    "    exit()\n",
    "df = pd.read_excel(raw_file_path)\n",
    "print(\"=\"*50)\n",
    "print(f\"ğŸ“Š åŸå§‹æ•°æ®æ¦‚å†µï¼šæ€»è¡Œæ•°={len(df)}ï¼Œå­—æ®µ={df.columns.tolist()}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "# ---------------------- 2. ç­›é€‰ç›¸å…³å•†å®¶ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰ ----------------------\n",
    "def filter_pet_funeral_merchants(df):\n",
    "    core_keywords = ['å® ç‰©æ®¡è‘¬', 'å® ç‰©ç«åŒ–', 'å® ç‰©å–„å', 'å® ç‰©å–„ç»ˆ','å£è‘¬','å®‰è‘¬','å® ç‰©å¤©å ‚','å–„ç»ˆ',\n",
    "                    'å® ç‰©å®‰è‘¬', 'å® ç‰©è‘¬ç¤¼', 'å® ç‰©çºªå¿µ', 'æ¯›å­©å­æ®¡è‘¬','ç«åŒ–','ç”Ÿå‘½çºªå¿µ','å® ç‰©å‘Šåˆ«','æ®¡ä»ª']\n",
    "    keyword_condition = (\n",
    "        df['name'].astype(str).str.contains('|'.join(core_keywords), case=False) | \n",
    "        df['address'].astype(str).str.contains('|'.join(core_keywords), case=False) | \n",
    "        df['comment_num'].astype(str).str.contains('|'.join(core_keywords), case=False)\n",
    "    )\n",
    "    # ç­›é€‰åå»é‡\n",
    "    df_filtered = df[keyword_condition].drop_duplicates(subset=['name', 'address'], keep='first').reset_index(drop=True)\n",
    "    return df_filtered\n",
    "\n",
    "df_related = filter_pet_funeral_merchants(df)\n",
    "\n",
    "\n",
    "# ---------------------- 3. æ ¸å¿ƒä¿®å¤ï¼šå‡†ç¡®ç»Ÿè®¡â€œæ— è¯„åˆ†ï¼ˆå«0.0åˆ†ï¼‰â€çš„å•†å®¶ ----------------------\n",
    "def count_no_star_merchants(df):\n",
    "    \"\"\"ç»Ÿè®¡æ‰€æœ‰æ— è¯„åˆ†çš„å•†å®¶ï¼ˆå«0.0åˆ†ã€ç©ºå€¼ã€â€œæ— è¯„åˆ†â€æ–‡æœ¬ç­‰ï¼‰\"\"\"\n",
    "    # å®šä¹‰â€œæ— è¯„åˆ†â€çš„åˆ¤æ–­æ¡ä»¶ï¼ˆè¦†ç›–æ‰€æœ‰åœºæ™¯ï¼‰\n",
    "    no_star_condition = (\n",
    "        # åœºæ™¯1ï¼šfloatæ ¼å¼çš„0.0åˆ†\n",
    "        (df['star'] == 0.0) | \n",
    "        # åœºæ™¯2ï¼šå­—ç¬¦ä¸²æ ¼å¼çš„â€œ0.0åˆ†â€â€œ0åˆ†â€\n",
    "        df['star'].astype(str).str.contains(r'^0\\.0åˆ†$|^0åˆ†$', regex=True) | \n",
    "        # åœºæ™¯3ï¼šç©ºå€¼ã€ç©ºå­—ç¬¦ä¸²\n",
    "        (df['star'].isna()) | (df['star'].astype(str) == '') | \n",
    "        # åœºæ™¯4ï¼šæ˜ç¡®çš„â€œæ— è¯„åˆ†â€æ–‡æœ¬\n",
    "        (df['star'] == 'æ— è¯„åˆ†') | (df['star'] == 'æš‚æ— è¯„åˆ†')\n",
    "    )\n",
    "    # ç»Ÿè®¡ç¬¦åˆæ¡ä»¶çš„å•†å®¶æ•°é‡\n",
    "    no_star_count = len(df[no_star_condition])\n",
    "    # è¿”å›æ•°é‡å’Œå¯¹åº”çš„å•†å®¶æ•°æ®ï¼ˆä¾¿äºéªŒè¯ï¼‰\n",
    "    no_star_merchants = df[no_star_condition]\n",
    "    return no_star_count, no_star_merchants\n",
    "\n",
    "\n",
    "# ---------------------- 4. é‡æ–°ç»Ÿè®¡å¹¶éªŒè¯ ----------------------\n",
    "# ç»Ÿè®¡ç›¸å…³å•†å®¶ä¸­çš„æ— è¯„åˆ†æ•°é‡\n",
    "no_star_count, no_star_merchants = count_no_star_merchants(df_related)\n",
    "# ç»Ÿè®¡æ— äººå‡ä»·æ ¼çš„æ•°é‡ï¼ˆåŒæ­¥ä¼˜åŒ–ï¼Œé¿å…ç±»ä¼¼é”™è¯¯ï¼‰\n",
    "no_avg_price_count = len(df_related[\n",
    "    (df_related['avg_price'] == 'äººå‡ -') | (df_related['avg_price'].isna()) | (df_related['avg_price'].astype(str) == '')\n",
    "])\n",
    "# ç»Ÿè®¡æœ‰å®Œæ•´æ•°æ®ï¼ˆæœ‰äººå‡+æœ‰è¯„åˆ†ï¼‰çš„æ•°é‡\n",
    "complete_data_count = len(df_related) - no_avg_price_count - no_star_count\n",
    "\n",
    "\n",
    "# ---------------------- 5. ä¿å­˜ç­›é€‰ç»“æœ ----------------------\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "related_file_name = f\"pet_funeral_shenzhen_cleaned_{timestamp}.xlsx\"\n",
    "related_file_path = os.path.join(os.getcwd(), related_file_name)\n",
    "df_related.to_excel(related_file_path, index=False, engine='openpyxl')\n",
    "\n",
    "\n",
    "# ---------------------- 6. è¾“å‡ºå‡†ç¡®ç»“æœ ----------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ‰ ç­›é€‰å®Œæˆï¼ç›¸å…³å•†å®¶æ€»è¡Œæ•°ï¼š{len(df_related)}\")\n",
    "print(f\"ğŸ“ ä¿å­˜è·¯å¾„ï¼š{related_file_path}\")\n",
    "print(\"\\nğŸ“‹ ç›¸å…³å•†å®¶æ•°æ®å®Œæ•´æ€§ç»Ÿè®¡ï¼ˆä¿®å¤åï¼‰ï¼š\")\n",
    "print(f\"1. å«'äººå‡ -'/æ— äººå‡çš„å•†å®¶ï¼š{no_avg_price_count} å®¶\")\n",
    "print(f\"2. æ— è¯„åˆ†ï¼ˆå«0.0åˆ†ï¼‰çš„å•†å®¶ï¼š{no_star_count} å®¶\")  # ä¿®å¤åçš„ç»Ÿè®¡ç»“æœ\n",
    "print(f\"3. åŒæ—¶æœ‰äººå‡+æœ‰è¯„åˆ†çš„å•†å®¶ï¼š{complete_data_count} å®¶\")\n",
    "print(\"\\nğŸ” æ— è¯„åˆ†å•†å®¶é¢„è§ˆï¼ˆå‰3å®¶ï¼Œè‹¥æœ‰ï¼‰ï¼š\")\n",
    "if no_star_count > 0:\n",
    "    print(no_star_merchants[['name', 'avg_price', 'star', 'address']].head(3))\n",
    "else:\n",
    "    print(\"   æš‚æ— æ— è¯„åˆ†çš„ç›¸å…³å•†å®¶\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# å¯é€‰ï¼šéªŒè¯åŸå§‹è¯„åˆ†å­—æ®µçš„æ ¼å¼ï¼ˆå¸®åŠ©ä½ ç¡®è®¤æ•°æ®å®é™…æƒ…å†µï¼‰\n",
    "print(f\"\\nğŸ“Š åŸå§‹è¯„åˆ†å­—æ®µï¼ˆstarï¼‰çš„å”¯ä¸€å€¼ç¤ºä¾‹ï¼š\")\n",
    "unique_stars = df_related['star'].unique()[:10]  # æ‰“å°å‰10ä¸ªå”¯ä¸€å€¼\n",
    "for star in unique_stars:\n",
    "    print(f\"   æ ¼å¼={type(star).__name__}, å€¼='{star}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083e1baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š åœ°å€åˆ†åŒºç»“æœç»Ÿè®¡ï¼ˆå…±39æ¡æ•°æ®ï¼‰ï¼š\n",
      "   é¾™å²—åŒºï¼š10æ¡ï¼ˆå æ¯”ï¼š25.6%ï¼‰\n",
      "   å—å±±åŒºï¼š9æ¡ï¼ˆå æ¯”ï¼š23.1%ï¼‰\n",
      "   é¾™ååŒºï¼š6æ¡ï¼ˆå æ¯”ï¼š15.4%ï¼‰\n",
      "   å®å®‰åŒºï¼š6æ¡ï¼ˆå æ¯”ï¼š15.4%ï¼‰\n",
      "   ç¦ç”°åŒºï¼š4æ¡ï¼ˆå æ¯”ï¼š10.3%ï¼‰\n",
      "   ç½—æ¹–åŒºï¼š3æ¡ï¼ˆå æ¯”ï¼š7.7%ï¼‰\n",
      "   å…‰æ˜åŒºï¼š1æ¡ï¼ˆå æ¯”ï¼š2.6%ï¼‰\n",
      "\n",
      "âœ… æ¸…æ´—å®Œæˆï¼å¸¦è¡Œæ”¿åŒºçš„æ•°æ®å·²ä¿å­˜è‡³ï¼šshenzhen_second_cleaned_20251115.xlsx\n",
      "   ï¼ˆè¯·å…ˆæ£€æŸ¥è¯¥æ–‡ä»¶ä¸­çš„ 'district_cn' åˆ—ï¼Œç¡®è®¤åˆ†åŒºæ­£ç¡®åï¼Œå†è¿è¡Œçƒ­åŠ›å›¾ä»£ç ï¼‰\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------------------- é…ç½®å‚æ•°ï¼ˆè¯·ä¿®æ”¹ä¸ºä½ çš„å®é™…è·¯å¾„ï¼‰ ----------------------\n",
    "INPUT_RAW_DATA = \"/Users/syx/Documents/pythonè„šæœ¬/pet_funeral_shenzhen_cleaned_20251115_001632.xlsx\"  # æ·±åœ³åŸå§‹æ•°æ®è·¯å¾„\n",
    "OUTPUT_CLEANED_DATA = f\"shenzhen_second_cleaned_{datetime.now().strftime('%Y%m%d')}.xlsx\"  # è¾“å‡ºè·¯å¾„\n",
    "\n",
    "\n",
    "# ---------------------- æ ¸å¿ƒï¼šæ·±åœ³åœ°å€ç²¾å‡†åˆ†åŒºå‡½æ•° ----------------------\n",
    "def address_to_district(address):\n",
    "    \"\"\"å°†åœ°å€æ˜ å°„åˆ°æ·±åœ³è¡Œæ”¿åŒºï¼ˆè¦†ç›–è¥¿ä¸½ã€ç§‘æŠ€å›­ã€é¾™åç­‰æ‰€æœ‰æä¾›çš„åœ°ç‚¹ï¼‰\"\"\"\n",
    "    if pd.isna(address):\n",
    "        return \"åœ°å€ç¼ºå¤±\"\n",
    "    \n",
    "    addr = str(address).strip().replace(\" \", \"\").lower()\n",
    "    if addr == \"\":\n",
    "        return \"åœ°å€ç¼ºå¤±\"\n",
    "\n",
    "    # æ·±åœ³åœ°ç‚¹-è¡Œæ”¿åŒºæ˜ å°„è¡¨ï¼ˆä¸¥æ ¼æŒ‰æ·±åœ³æœ€æ–°è¡Œæ”¿è§„åˆ’ï¼Œè¦†ç›–æ‰€æœ‰æä¾›çš„åœ°ç‚¹ï¼‰\n",
    "    district_mapping = {\n",
    "        # å—å±±åŒºï¼ˆå«è¥¿ä¸½ã€ç§‘æŠ€å›­ã€å—å¤´ç­‰ï¼‰\n",
    "        \"å—å±±åŒº\": [\"å—å±±åŒº\", \"å—å±±\", \"è¥¿ä¸½\", \"ç§‘æŠ€å›­\", \"å—å¤´\"],\n",
    "        # ç¦ç”°åŒºï¼ˆå«å…«å¦å²­ã€å›­å²­ã€æ™¯ç”°ç­‰ï¼‰\n",
    "        \"ç¦ç”°åŒº\": [\"ç¦ç”°åŒº\", \"ç¦ç”°\", \"å…«å¦å²­\", \"å›­å²­\", \"æ™¯ç”°\", \"ç¦ç”°ä¸­å¿ƒ\", \"å²—å¦\"],  # æ¢…æ—å…³ä¸»ä½“å±é¾™åï¼Œä½†å¸¸å…³è”ç¦ç”°ï¼Œæ­¤å¤„æŒ‰è¡Œæ”¿å½’å±é¾™åï¼Œç¦ç”°å…³é”®è¯ä¸å«æ¢…æ—å…³\n",
    "        # é¾™ååŒºï¼ˆå«å¤§æµªã€æ°‘æ²»ã€é¾™åç­‰ï¼‰\n",
    "        \"é¾™ååŒº\": [\"é¾™ååŒº\", \"é¾™å\", \"å¤§æµª\", \"æ°‘æ²»\", \"æ¢…æ—å…³\"],  # æ¢…æ—å…³è¡Œæ”¿å±é¾™ååŒº\n",
    "        # é¾™å²—åŒºï¼ˆå«å‚ç”°ã€ç½—å²—ã€å¤§èŠ¬ç­‰ï¼‰\n",
    "        \"é¾™å²—åŒº\": [\"é¾™å²—åŒº\", \"é¾™å²—\", \"å‚ç”°\", \"æ¨ç¾\", \"åå—åŸ\", \"é¾™å²—ä¸‡è¾¾å¹¿åœº\", \"ç½—å²—\", \"æ±‚æ°´å±±\", \"é¾™å²—ä¸­å¿ƒåŸåŒº\", \n",
    "                  \"ä»æ’æ¢¦ä¸­å¿ƒ\", \"å¤§èŠ¬\", \"å—å²­\", \"å²—å¤´\", \"é›ªè±¡\", \"å¹³æ¹–\"],\n",
    "        # å®å®‰åŒºï¼ˆå«æ²™äº•ã€å›ºæˆã€è¥¿ä¹¡ç­‰ï¼‰\n",
    "        \"å®å®‰åŒº\": [\"å®å®‰åŒº\", \"å®å®‰\", \"æ²™äº•\", \"å›ºæˆ\", \"çŸ³å²©\", \"æ–°å®‰\", \"è¥¿ä¹¡\"],\n",
    "        # ç½—æ¹–åŒºï¼ˆå«è²å¡˜ã€è‰åŸ”ã€ç¬‹å²—ç­‰ï¼‰\n",
    "        \"ç½—æ¹–åŒº\": [\"ç½—æ¹–åŒº\", \"ç½—æ¹–\", \"è²å¡˜\", \"è‰åŸ”\", \"ç¬‹å²—\"],\n",
    "        # å…‰æ˜åŒºï¼ˆå«å…¬æ˜ï¼‰\n",
    "        \"å…‰æ˜åŒº\": [\"å…‰æ˜åŒº\", \"å…‰æ˜\", \"å…¬æ˜\"],\n",
    "        # å…¶ä»–åŒºï¼ˆé¢„ç•™æ‰©å±•ï¼Œå¦‚ç›ç”°åŒºã€åªå±±åŒºç­‰ï¼‰\n",
    "        \"ç›ç”°åŒº\": [\"ç›ç”°åŒº\", \"ç›ç”°\"],\n",
    "        \"åªå±±åŒº\": [\"åªå±±åŒº\", \"åªå±±\"],\n",
    "        \"å¤§é¹æ–°åŒº\": [\"å¤§é¹æ–°åŒº\", \"å¤§é¹\"]\n",
    "    }\n",
    "\n",
    "    # ç²¾å‡†åŒ¹é…ï¼šä¼˜å…ˆåŒ¹é…å®Œæ•´å…³é”®è¯ï¼ˆå¦‚â€œå…«å¦å²­/å›­å²­â€ä¼šåŒ¹é…â€œå…«å¦å²­â€æˆ–â€œå›­å²­â€ï¼‰\n",
    "    for district, keywords in district_mapping.items():\n",
    "        for kw in keywords:\n",
    "            if kw in addr:\n",
    "                return district\n",
    "\n",
    "    return \"å¾…ç¡®è®¤ï¼ˆéœ€äººå·¥æ ¸å¯¹ï¼‰\"  # æœªåŒ¹é…åˆ°çš„åœ°å€ï¼ˆæå°‘ï¼‰\n",
    "\n",
    "\n",
    "# ---------------------- æ‰§è¡Œæ¸…æ´—åˆ†åŒº ----------------------\n",
    "if not os.path.exists(INPUT_RAW_DATA):\n",
    "    print(f\"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°åŸå§‹æ•°æ®æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼š{INPUT_RAW_DATA}\")\n",
    "else:\n",
    "    # è¯»å–åŸå§‹æ•°æ®\n",
    "    df = pd.read_excel(INPUT_RAW_DATA)\n",
    "    if \"address\" not in df.columns:\n",
    "        print(f\"âŒ é”™è¯¯ï¼šåŸå§‹æ•°æ®ä¸­æœªæ‰¾åˆ° 'address' åˆ—ï¼Œè¯·ç¡®è®¤åˆ—åæ­£ç¡®\")\n",
    "    else:\n",
    "        # å¤„ç†addressåˆ—ï¼Œæ–°å¢è¡Œæ”¿åŒºåˆ—ï¼ˆdistrict_cnï¼‰\n",
    "        df[\"district_cn\"] = df[\"address\"].apply(address_to_district)\n",
    "        \n",
    "        # ç»Ÿè®¡åˆ†åŒºç»“æœï¼ˆæ–¹ä¾¿æ£€æŸ¥å‡†ç¡®æ€§ï¼‰\n",
    "        print(f\"\\nğŸ“Š åœ°å€åˆ†åŒºç»“æœç»Ÿè®¡ï¼ˆå…±{len(df)}æ¡æ•°æ®ï¼‰ï¼š\")\n",
    "        district_stats = df[\"district_cn\"].value_counts()\n",
    "        for dist, cnt in district_stats.items():\n",
    "            print(f\"   {dist}ï¼š{cnt}æ¡ï¼ˆå æ¯”ï¼š{cnt/len(df)*100:.1f}%ï¼‰\")\n",
    "        \n",
    "        # ä¿å­˜æ¸…æ´—åçš„æ•°æ®ï¼ˆå«è¡Œæ”¿åŒºåˆ—ï¼‰\n",
    "        df.to_excel(OUTPUT_CLEANED_DATA, index=False, engine=\"openpyxl\")\n",
    "        print(f\"\\nâœ… æ¸…æ´—å®Œæˆï¼å¸¦è¡Œæ”¿åŒºçš„æ•°æ®å·²ä¿å­˜è‡³ï¼š{OUTPUT_CLEANED_DATA}\")\n",
    "        print(f\"   ï¼ˆè¯·å…ˆæ£€æŸ¥è¯¥æ–‡ä»¶ä¸­çš„ 'district_cn' åˆ—ï¼Œç¡®è®¤åˆ†åŒºæ­£ç¡®åï¼Œå†è¿è¡Œçƒ­åŠ›å›¾ä»£ç ï¼‰\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
