import requests
import pandas as pd
import time
import random
from datetime import datetime
import json

class BilibiliCommentCrawler:
   
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://www.bilibili.com/',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Origin': 'https://www.bilibili.com'
        })
        
    def get_video_info(self, aid: int = 371839463) -> dict:
        """è·å–è§†é¢‘ä¿¡æ¯"""
        try:
            url = "https://api.bilibili.com/x/web-interface/view"
            params = {'aid': aid}
            
            response = self.session.get(url, params=params, timeout=10)
            data = response.json()
            
            if data.get('code') == 0:
                video_info = data['data']
                print(f"è§†é¢‘æ ‡é¢˜: {video_info.get('title')}")
                print(f"UPä¸»: {video_info.get('owner', {}).get('name')}")
                print(f"æ’­æ”¾é‡: {video_info.get('stat', {}).get('view')}")
                print(f"å¼¹å¹•æ•°: {video_info.get('stat', {}).get('danmaku')}")
                return video_info
            else:
                print(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {data.get('message')}")
                return {}
                
        except Exception as e:
            print(f"è·å–è§†é¢‘ä¿¡æ¯å‡ºé”™: {e}")
            return {}
    
    def get_comments_page(self, oid: int = 371839463, page: int = 1) -> dict:
        """è·å–å•é¡µè¯„è®ºæ•°æ®"""
        try:
            url = "https://api.bilibili.com/x/v2/reply"
            params = {
                'pn': page,          # é¡µç 
                'type': 1,           # 1è¡¨ç¤ºè§†é¢‘
                'oid': oid,          # è§†é¢‘aid
                'sort': 2,           # 2æŒ‰çƒ­åº¦æ’åºï¼Œ1æŒ‰æ—¶é—´æ’åº
                'ps': 20,            # æ¯é¡µæ¡æ•°
                'nohot': 0           # æ˜¯å¦éšè—çƒ­è¯„ï¼Œ0ä¸ºä¸éšè—
            }
            
            response = self.session.get(url, params=params, timeout=10)
            data = response.json()
            
            if data.get('code') == 0:
                return data
            else:
                print(f"ç¬¬{page}é¡µè¯„è®ºè·å–å¤±è´¥: {data.get('message')}")
                return {}
                
        except Exception as e:
            print(f"è·å–ç¬¬{page}é¡µè¯„è®ºå‡ºé”™: {e}")
            return {}
    
    def get_sub_comments(self, root_id: int, oid: int = 371839463, page: int = 1) -> dict:
        """è·å–å­è¯„è®ºï¼ˆæ¥¼ä¸­æ¥¼ï¼‰"""
        try:
            url = "https://api.bilibili.com/x/v2/reply/detail"
            params = {
                'pn': page,
                'type': 1,
                'oid': oid,
                'root': root_id,  # çˆ¶è¯„è®ºID
                'ps': 10          # å­è¯„è®ºæ¯é¡µæ¡æ•°
            }
            
            response = self.session.get(url, params=params, timeout=10)
            data = response.json()
            
            if data.get('code') == 0:
                return data
            else:
                print(f"è·å–å­è¯„è®ºå¤±è´¥: {data.get('message')}")
                return {}
                
        except Exception as e:
            print(f"è·å–å­è¯„è®ºå‡ºé”™: {e}")
            return {}
    
    def parse_comment(self, comment_data: dict, video_id: int = 371839463) -> dict:
        
        try:
            # åŸºæœ¬ä¿¡æ¯
            rpid = comment_data.get('rpid', 0)
            parent = comment_data.get('parent', 0)
            
            # æ—¶é—´å¤„ç†
            ctime = comment_data.get('ctime', 0)
            mtime = comment_data.get('mtime', ctime)
            
            # ç”¨æˆ·ä¿¡æ¯
            member = comment_data.get('member', {})
            
            # è¯„è®ºå†…å®¹
            content = comment_data.get('content', {})
            message = content.get('message', '')
            
            # è¡¨æƒ…å¤„ç†ï¼ˆå¦‚æœæœ‰ï¼‰
            if 'emote' in content and content['emote']:
                # å°†è¡¨æƒ…ä»£ç æ›¿æ¢ä¸ºæè¿°
                for key, emote in content['emote'].items():
                    if key in message:
                        message = message.replace(key, f"[{emote.get('text', 'è¡¨æƒ…')}]")
            
            comment = {
                'comment_id': str(rpid),
                'parent_comment_id': str(parent),
                'create_time': ctime,
                'video_id': str(video_id),
                'content': message,
                'user_id': str(member.get('mid', '')),
                'nickname': member.get('uname', ''),
                'avatar': member.get('avatar', ''),
                'sub_comment_count': comment_data.get('rcount', 0),
                'last_modify_ts': mtime,
                'like_count': comment_data.get('like', 0),
                'user_level': member.get('level_info', {}).get('current_level', 0),
                'vip_status': 1 if member.get('vip', {}).get('status') == 1 else 0,
                'official_verify': member.get('official_verify', {}).get('desc', '')
            }
            
            return comment
            
        except Exception as e:
            print(f"è§£æè¯„è®ºæ•°æ®å‡ºé”™: {e}")
            return {}
    
    def crawl_comments(self, 
                      max_pages: int = 100, 
                      max_sub_pages: int = 3,
                      delay_base: float = 1.0) -> list:
        """
        çˆ¬å–è¯„è®ºä¸»å‡½æ•°
        
        å‚æ•°:
            max_pages: æœ€å¤§çˆ¬å–é¡µæ•°ï¼ˆæ¯é¡µçº¦20æ¡ä¸»è¯„è®ºï¼‰
            max_sub_pages: æ¯ä¸ªè¯„è®ºæœ€å¤§å­è¯„è®ºé¡µæ•°
            delay_base: åŸºç¡€è¯·æ±‚å»¶è¿Ÿï¼ˆç§’ï¼‰
        """
        all_comments = []
        oid = 371839463  # è§†é¢‘aid
        
        print("=" * 60)
        print(f"å¼€å§‹çˆ¬å–Bç«™è§†é¢‘ 371839463 çš„è¯„è®º")
        print("=" * 60)
        
        # å…ˆè·å–è§†é¢‘ä¿¡æ¯
        video_info = self.get_video_info(oid)
        if video_info:
            print(f"è§†é¢‘ä¿¡æ¯è·å–æˆåŠŸï¼Œå¼€å§‹çˆ¬å–è¯„è®º...\n")
        
        current_page = 1
        
        while current_page <= max_pages:
            print(f"ğŸ“„ æ­£åœ¨çˆ¬å–ç¬¬ {current_page} é¡µä¸»è¯„è®º...")
            
            # è·å–å½“å‰é¡µè¯„è®º
            page_data = self.get_comments_page(oid, current_page)
            
            if not page_data:
                print(f"ç¬¬ {current_page} é¡µæ— æ•°æ®ï¼Œåœæ­¢çˆ¬å–")
                break
            
            replies = page_data.get('data', {}).get('replies', [])
            
            if not replies:
                print(f"ç¬¬ {current_page} é¡µæ²¡æœ‰è¯„è®ºï¼Œåœæ­¢çˆ¬å–")
                break
            
            print(f"  è·å–åˆ° {len(replies)} æ¡ä¸»è¯„è®º")
            
            # å¤„ç†å½“å‰é¡µçš„æ‰€æœ‰è¯„è®º
            for reply in replies:
                # è§£æä¸»è¯„è®º
                main_comment = self.parse_comment(reply)
                if main_comment:
                    all_comments.append(main_comment)
                    # print(f"    âœ“ ä¸»è¯„è®º: {main_comment['nickname']}: {main_comment['content'][:30]}...")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å­è¯„è®º
                rcount = reply.get('rcount', 0)
                if rcount > 0:
                    print(f"    è¯„è®º {reply.get('rpid')} æœ‰ {rcount} æ¡å›å¤ï¼Œå¼€å§‹çˆ¬å–å­è¯„è®º...")
                    
                    # çˆ¬å–å­è¯„è®º
                    sub_comments_list = self.crawl_sub_comments(
                        root_id=reply['rpid'],
                        total_count=rcount,
                        max_sub_pages=max_sub_pages
                    )
                    
                    # æ·»åŠ å­è¯„è®ºåˆ°æ€»åˆ—è¡¨
                    for sub_comment in sub_comments_list:
                        all_comments.append(sub_comment)
            
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€é¡µ
            cursor = page_data.get('data', {}).get('cursor', {})
            if cursor.get('is_end', True):
                print("\nâœ… å·²åˆ°è¾¾æœ€åä¸€é¡µï¼Œçˆ¬å–å®Œæˆï¼")
                break
            
            current_page += 1
            
            # éšæœºå»¶è¿Ÿï¼Œé¿å…è¢«å°
            delay = delay_base + random.uniform(0.5, 1.5)
            print(f"â³ ç­‰å¾… {delay:.1f} ç§’åç»§ç»­...")
            time.sleep(delay)
        
        print(f"\nğŸ‰ çˆ¬å–å®Œæˆï¼å…±è·å– {len(all_comments)} æ¡è¯„è®º")
        return all_comments
    
    def crawl_sub_comments(self, root_id: int, total_count: int, max_sub_pages: int = 3) -> list:
        """çˆ¬å–ç‰¹å®šè¯„è®ºçš„æ‰€æœ‰å­è¯„è®º"""
        sub_comments = []
        oid = 371839463
        page = 1
        
        while page <= max_sub_pages:
            sub_data = self.get_sub_comments(root_id, oid, page)
            
            if not sub_data:
                break
            
            replies = sub_data.get('data', {}).get('replies', [])
            
            if not replies:
                break
            
            for reply in replies:
                sub_comment = self.parse_comment(reply)
                if sub_comment:
                    sub_comments.append(sub_comment)
            
            # å¦‚æœè·å–çš„å›å¤æ•°å°‘äº10æ¡ï¼Œé€šå¸¸è¡¨ç¤ºæ²¡æœ‰æ›´å¤šäº†
            if len(replies) < 10:
                break
            
            page += 1
            time.sleep(0.5 + random.uniform(0, 0.3))
        
        print(f"      å·²è·å– {len(sub_comments)} æ¡å­è¯„è®º")
        return sub_comments
    
    def save_to_excel(self, comments: list, filename: str = None):
        """ä¿å­˜è¯„è®ºæ•°æ®åˆ°Excel"""
        if not comments:
            print("âš ï¸ æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return
        
        if filename is None:
            filename = f"Bç«™è¯„è®ºæ•°æ®_video_371839463_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(comments)
        
        # æ·»åŠ å¯è¯»æ—¶é—´åˆ—
        df['create_time_str'] = df['create_time'].apply(
            lambda x: datetime.fromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S') if x else ''
        )
        
        df['last_modify_str'] = df['last_modify_ts'].apply(
            lambda x: datetime.fromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S') if x else ''
        )
        
        # æ’åºï¼šå…ˆæŒ‰ä¸»è¯„è®ºæ—¶é—´ï¼Œå†æŒ‰è¯„è®ºIDï¼ˆç¡®ä¿çˆ¶å­å…³ç³»ï¼‰
        df['comment_id_num'] = df['comment_id'].astype(int)
        df['parent_id_num'] = df['parent_comment_id'].astype(int)
        df = df.sort_values(['create_time', 'comment_id_num']).reset_index(drop=True)
        
        # åˆ é™¤ä¸´æ—¶åˆ—
        df = df.drop(['comment_id_num', 'parent_id_num'], axis=1)
        
        # ä¿å­˜åˆ°Excel
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='video_371839463', index=False)
            
            # æ·»åŠ ä¸€ä¸ªç»Ÿè®¡ä¿¡æ¯sheet
            stats_df = self.create_statistics(df)
            stats_df.to_excel(writer, sheet_name='ç»Ÿè®¡æ•°æ®', index=False)
        
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
        
        # åŒæ—¶ä¿å­˜ä¸ºCSVï¼ˆä¾¿äºæŸ¥çœ‹ï¼‰
        csv_filename = filename.replace('.xlsx', '.csv')
        df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
        print(f"ğŸ“„ CSVå¤‡ä»½å·²ä¿å­˜åˆ°: {csv_filename}")
        
        return filename
    
    def create_statistics(self, df: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºç»Ÿè®¡æ•°æ®"""
        stats = []
        
        # åŸºç¡€ç»Ÿè®¡
        total_comments = len(df)
        main_comments = len(df[df['parent_comment_id'] == '0'])
        sub_comments = total_comments - main_comments
        
        stats.append({'æŒ‡æ ‡': 'æ€»è¯„è®ºæ•°', 'æ•°å€¼': total_comments})
        stats.append({'æŒ‡æ ‡': 'ä¸»è¯„è®ºæ•°', 'æ•°å€¼': main_comments})
        stats.append({'æŒ‡æ ‡': 'å­è¯„è®ºæ•°', 'æ•°å€¼': sub_comments})
        stats.append({'æŒ‡æ ‡': 'å›å¤ç‡', 'æ•°å€¼': f"{sub_comments/max(main_comments,1):.1%}"})
        
        # ç‚¹èµç»Ÿè®¡
        max_like = df['like_count'].max()
        avg_like = df['like_count'].mean()
        total_like = df['like_count'].sum()
        
        stats.append({'æŒ‡æ ‡': 'æœ€é«˜ç‚¹èµæ•°', 'æ•°å€¼': int(max_like)})
        stats.append({'æŒ‡æ ‡': 'å¹³å‡ç‚¹èµæ•°', 'æ•°å€¼': f"{avg_like:.1f}"})
        stats.append({'æŒ‡æ ‡': 'æ€»ç‚¹èµæ•°', 'æ•°å€¼': int(total_like)})
        
        # ç”¨æˆ·ç­‰çº§ç»Ÿè®¡
        if 'user_level' in df.columns:
            level_counts = df['user_level'].value_counts().sort_index()
            for level, count in level_counts.items():
                stats.append({'æŒ‡æ ‡': f'Lv{level}ç”¨æˆ·æ•°', 'æ•°å€¼': int(count)})
        
        # VIPç”¨æˆ·ç»Ÿè®¡
        if 'vip_status' in df.columns:
            vip_count = df['vip_status'].sum()
            stats.append({'æŒ‡æ ‡': 'VIPç”¨æˆ·æ•°', 'æ•°å€¼': int(vip_count)})
            stats.append({'æŒ‡æ ‡': 'VIPæ¯”ä¾‹', 'æ•°å€¼': f"{vip_count/total_comments:.1%}"})
        
        # æ—¶é—´èŒƒå›´
        if 'create_time' in df.columns:
            min_time = df['create_time'].min()
            max_time = df['create_time'].max()
            if min_time and max_time:
                time_range = datetime.fromtimestamp(max_time) - datetime.fromtimestamp(min_time)
                stats.append({'æŒ‡æ ‡': 'æœ€æ—©è¯„è®ºæ—¶é—´', 'æ•°å€¼': datetime.fromtimestamp(min_time).strftime('%Y-%m-%d %H:%M:%S')})
                stats.append({'æŒ‡æ ‡': 'æœ€æ™šè¯„è®ºæ—¶é—´', 'æ•°å€¼': datetime.fromtimestamp(max_time).strftime('%Y-%m-%d %H:%M:%S')})
                stats.append({'æŒ‡æ ‡': 'è¯„è®ºæ—¶é—´è·¨åº¦', 'æ•°å€¼': f"{time_range.days}å¤©{time_range.seconds//3600}å°æ—¶"})
        
        return pd.DataFrame(stats)
    
    def print_summary(self, comments: list):
        """æ‰“å°çˆ¬å–ç»“æœæ‘˜è¦"""
        if not comments:
            return
        
        df = pd.DataFrame(comments)
        
        print("\n" + "=" * 60)
        print("ğŸ“Š çˆ¬å–ç»“æœæ‘˜è¦")
        print("=" * 60)
        
        # åŸºæœ¬ç»Ÿè®¡
        total = len(df)
        main_comments = len(df[df['parent_comment_id'] == '0'])
        sub_comments = total - main_comments
        
        print(f"æ€»è¯„è®ºæ•°: {total}")
        print(f"ä¸»è¯„è®ºæ•°: {main_comments}")
        print(f"å­è¯„è®ºæ•°: {sub_comments}")
        print(f"å›å¤ç‡: {sub_comments/max(main_comments,1):.1%}")
        
        # ç‚¹èµåˆ†æ
        max_like = df['like_count'].max()
        avg_like = df['like_count'].mean()
        
        # æ‰¾å‡ºç‚¹èµæœ€é«˜çš„è¯„è®º
        top_like = df.loc[df['like_count'].idxmax()] if max_like > 0 else None
        if top_like is not None and not pd.isna(top_like['nickname']):
            print(f"\nğŸ† æœ€é«˜ç‚¹èµè¯„è®º:")
            print(f"   ç”¨æˆ·: {top_like['nickname']}")
            print(f"   ç‚¹èµ: {int(top_like['like_count'])}")
            print(f"   å†…å®¹: {top_like['content'][:50]}...")
        
        print(f"\nğŸ“ˆ ç‚¹èµç»Ÿè®¡:")
        print(f"   æœ€é«˜ç‚¹èµ: {int(max_like)}")
        print(f"   å¹³å‡ç‚¹èµ: {avg_like:.1f}")
        
        # ç”¨æˆ·åˆ†æ
        unique_users = df['user_id'].nunique()
        print(f"\nğŸ‘¥ ç”¨æˆ·ç»Ÿè®¡:")
        print(f"   å‚ä¸ç”¨æˆ·æ•°: {unique_users}")
        print(f"   äººå‡è¯„è®ºæ•°: {total/max(unique_users,1):.1f}")
        
        # çƒ­é—¨ç”¨æˆ·ï¼ˆè¯„è®ºæœ€å¤šçš„ç”¨æˆ·ï¼‰
        top_users = df['nickname'].value_counts().head(5)
        if not top_users.empty:
            print(f"   è¯„è®ºæœ€å¤šç”¨æˆ·TOP5:")
            for i, (user, count) in enumerate(top_users.items(), 1):
                print(f"     {i}. {user}: {count}æ¡")
        
        print("=" * 60)


def main():
    """ä¸»å‡½æ•° - è¿è¡Œçˆ¬è™«"""
    print("ğŸš€ Bç«™è§†é¢‘è¯„è®ºçˆ¬è™«å¯åŠ¨")
    print("ç›®æ ‡è§†é¢‘ID: 371839463\n")
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    crawler = BilibiliCommentCrawler()
    
    # è®¾ç½®çˆ¬å–å‚æ•°
    max_pages = 200        # æœ€å¤§çˆ¬å–é¡µæ•°ï¼ˆæ¯é¡µçº¦20æ¡ä¸»è¯„è®ºï¼‰
    max_sub_pages = 10     # æ¯ä¸ªè¯„è®ºæœ€å¤§å­è¯„è®ºé¡µæ•°
    delay = 2.5          # åŸºç¡€å»¶è¿Ÿï¼ˆç§’ï¼‰
    
    try:
        # å¼€å§‹çˆ¬å–
        comments = crawler.crawl_comments(
            max_pages=max_pages,
            max_sub_pages=max_sub_pages,
            delay_base=delay
        )
        
        if comments:
            # æ˜¾ç¤ºæ‘˜è¦
            crawler.print_summary(comments)
            
            # ä¿å­˜æ•°æ®
            filename = crawler.save_to_excel(comments)
            
            print(f"\nâœ… ä»»åŠ¡å®Œæˆï¼")
            print(f"ğŸ“ æ•°æ®æ–‡ä»¶: {filename}")
        else:
            print("\nâŒ æœªèƒ½è·å–åˆ°è¯„è®ºæ•°æ®")
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ çˆ¬å–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
